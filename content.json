{"meta":{"title":"着陆的橘子","subtitle":null,"description":null,"author":"AaronShi","url":"https://aaronshi32.github.io"},"pages":[],"posts":[{"title":"读书笔记-Redis 多机数据库的实现","slug":"读书笔记-Redis 多机数据库的实现","date":"2018-04-05T09:56:15.000Z","updated":"2018-04-05T09:56:43.008Z","comments":true,"path":"2018/04/05/读书笔记-Redis 多机数据库的实现/","link":"","permalink":"https://aaronshi32.github.io/2018/04/05/读书笔记-Redis 多机数据库的实现/","excerpt":"","text":"","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-Redis 单机数据库的实现","slug":"读书笔记-Redis 单机数据库的实现","date":"2018-04-02T05:55:51.000Z","updated":"2018-04-05T09:56:01.609Z","comments":true,"path":"2018/04/02/读书笔记-Redis 单机数据库的实现/","link":"","permalink":"https://aaronshi32.github.io/2018/04/02/读书笔记-Redis 单机数据库的实现/","excerpt":"","text":"Redis：单机数据库的实现1. 数据库通过 SELECT num 命令可以切换客户端使用的数据库, 即让客户端 db 指针指向服务端的某个 db 元素 1234567891011121314151617181920212223242526272829struct redisServer &#123; // 一个数组, 保存着服务器中的所有数据库 redisDb *db; // 服务器的数据库数量: 默认16个 int dbnum; // AOF 缓冲区: 记录写操作 sds aof_buf; // AOF 重写缓冲区: 记录在 AOF 重写机制期间的所有写操作, 用于完成数据一致性 sds aof_rewrite_buf; // 一个链表, 保存了所有客户端状态 list *clients;&#125;struct redisClient &#123; // 记录客户端当前正在使用的数据库 redisDb *db; // 输入缓冲区: 用于保存客户端发送的命令请求 sds querybuf; // 命令的实现函数 struct redisCommand *cmd;&#125; Redis 是一个键值对(key-value pair)数据库服务器, 服务器中的每个数据库都由一个 redisDb 结构表示 12345678struct redisDb &#123; // 数据库键空间, 保存着数据库中的所有键值对 dict *dict; // 过期字典, 保存着键的过期时间, EXPIRE 实际上是操作该键值 dict *expires;&#125; 主要由 dict 和 expires 两个字典构成, 其中 dict 字典负责保存键值对, 而 expires 字典则负责保存键的过期时间 dict 内容是 &lt; StringObject - 对象 &gt; 的键值对, 当使用 Redis 命令对数据库进行读写时, 服务器不仅会对键空间执行指定的读写操作, 还会执行一些额外的维护操作, 其中包括: 在读取一个键之后, 服务器会根据键是否存在来更新服务器的键空间命中(hit)次数或不命中(miss)次数, 这两个值可以在 INFO stats 命令的 keyspace_hits 属性和 keyspace_misses 属性中查看 在读取一个键之后, 服务器会更新键的 LRU 时间, 用于计算键的闲置时间, 使用 OBJECT idletime 命令可以查看 key 的闲置时间 如果服务器在读取一个键时发现该键已经过期, 那么服务器会先删除这个过期键, 然后才执行余下的其他操作 如果有客户端使用 WATCH 命令监视了某个键, 那么服务器在对被监视的键进行修改之后, 会将这个键标记为 dirty, 从而让事务程序注意到这个键已经被修改过 服务器每次修改一个件之后, 都会对脏键计数器的值增 1, 这个计数器会触发服务器的持久化以及复制操作 如果服务器开启了数据库通知功能, 那么在对键进行修改之后, 服务器将按配置发送相应的数据库通知 当键过期时, Redis 提供了三种删除策略 (主动)定时删除: 在设置键的过期时间的同时, 创建一个定时器(timer), 让定时器在键的过期时间来临时, 立即执行对键的删除操作, 省内存, 费CPU (Redis使用)(被动)惰性删除: 放任键过期不管, 当获取的时候, 过期就删除, 未过期就返回, 省CPU, 费内存(expireIfNeeded) (Redis使用)(主动)定期删除: 每隔一段时间, 程序就对数据库进行一次检查, 删除里面的过期键(算法), 折中(serverCron - activeExpireCycle) AOF 和 RDB 是如何删除过期键的 执行 SAVE 命令或者 BGSAVE 命令所产生的新 RDB 文件不会包含已经过期的键 执行 BGREWRITEAOF 命令所产生的重写 AOF 文件不会包含已经过期的键 当一个过期键被删除之后, 服务器会追加一条 DEL 命令到现有 AOF 文件的末尾, 显式的删除过期键 当主服务器删除一个过期键之后, 它会向所有从服务器发送一条 DEL 命令, 显式的删除过期键 从服务器即使发现过期键也不会自作主张的删除它, 而是等待主节点发来 DEL 命令, 从而保证主从服务器数据一致性 2. RDB 持久化RDB 持久化操作, 即执行 SAVE/BGSAVE 命令, 是由配置文件中的 save 选项生效的, 由周期性操作函数 serverCron 每个 100ms 检查是否满足持久化条件 1234// defaultsave 900 1 900秒内对数据库至少1次修改save 300 10 300秒内对数据库至少10次修改save 60 10000 60秒内对数据库至少10000次修改 使用 od 命令工具可以查看 RDB 内容 SAVE 命令由服务器进程直接执行保存操作, 会阻塞服务器 BGSAVE 命令由子进行执行保存操作, 不会阻塞服务器执行, 但是会拒绝再次服务器进行再次接收的 SAVE, BGSAVE, BGREWRITEAOF 命令防止竞争 服务器状态中会保存所有用 save 选项设置的保存条件, 当任意一个保存条件被满足时, 服务器会自动执行 BGSAVE 命令 RDB 是一个经过压缩的二进制文件, 有多个部分组成 对于不同类型的键值对, RDB 文件会使用不同的方式来保存它们 3. AOF 持久化 AOF 持久化是通过保存 Redis 服务器所执行的写命令(SET、SADD、RPUSH)来记录数据库状态的, 这个保存的过程是由 serverCron 函数中的 flushAppendOnlyFile 来完成的, 也是由配置文件中的 appendfsync 选项来设置的 随着服务器时间的运行, AOF 中记录的写操作越来越多, 文件体积也越来越大, 使用 AOF 文件来进行数据还原所需的时间也就越多, 因此 AOF 文件重写机制: 通过读取服务器当前的数据库状态, 然后用一条命令去记录键值对, 代替之前记录这个键值对的多条命令 AOF 重写机制采用后台子进程的方式来实现, 虽然不阻塞服务器继续处理命令请求, 但随之而来带来了数据同步不一致的问题, 因此 Redis 服务器设置了一个 AOF 重写缓存区, 每次子进程重写完成时, 服务器进程将 AOF 缓冲区的记录追加到新的 AOF 文件末尾, 这也是 BGREWRITEAOF 命令的实现原理 4. 事件 Redis 服务器是一个事件驱动程序, 服务器处理的事件分为时间事件和文件事件两类 文件事件处理器是基于 Reactor 模式实现的网络通信程序 文件事件是对套接字操作的抽象: 每次套接字变为可应答(acceptable), 可写(writable)或者可读(readable)时, 相应的文件事件就会产生 文件事件分为 AE_READABLE 和 AE_WRITABLE 两类事件 时间事件分为定时事件和周期性事件 服务器一般情况下只执行 serverCron 函数的一个时间事件, 并且这个事件是周期性事件 时间事件的实际处理时间通常比设定的到达时间晚一些 5. 客户端通过使用由 I/O 多路复用技术实现的文件处理器, Redis 服务器使用单线程单进程的方式来处理命令请求, 并与多个客户端进行网络通信 12127.0.0.1:6379&gt; CLIENT listid=5 addr=127.0.0.1:58793 fd=8 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client 通过客户端的标志属性 flags 可以查明客户端的角色, 以及目前客户端所处的状态, 例如 123456789# 客户端是一个主服务器REDIS_MASTER# 客户端正在被列表命令阻塞REDIS_BLOCKED# 客户端正在执行事务, 但事务的安全性已被破坏REDIS_MULTI | REDIS_DIRTY_CAS# 客户端是一个从服务器, 并且版本低于 Redis 2.8REDIS_SLAVE | REDIS_PRE_PSYNC... 服务器状态结构使用 clients 链表连接多个客户端状态, 新添加的客户端状态会被放到链表的末尾 客户端状态的 flags 属性使用不同标志来表示客户端的角色, 以及客户端当前所处的状态 输入缓冲区记录了客户端发送的命令请求, 这个缓冲区的大小不能超过 1GB 命令参数和参数个数会被记录在客户端状态的 argv 和 argc 属性里面, 而 cmd 属性则记录对了客户端要执行命令是实现函数 客户端有固定大小缓冲区和可变大小缓冲区两种缓冲区可用, 其中固定大小缓冲区的最大大小为 16KB, 而可变大小缓冲区的最大大小不能超过服务器设置的硬性限制 输出缓冲区限制值有两种, 如果输出缓冲区的大小超过了服务器设置的硬性限制, 那么客户端会被立即关闭; 除此之外, 如果客户端在一定时间内, 一直超过服务器设置的软性限制, 那么客户端也会被关闭 当一个客户端通过网络连接上服务器时, 服务器会为这个客户端创建相应的客户端状态, 网络连接关闭、发送了不合协议格式的命令请求、成为 CLIENT KILL 命令的目标、空转时间超时、输出缓冲区的大小超出限制, 以上这些原因都会造客户端被关闭 处理 LUA 脚本的伪客户端在服务器初始化时创建, 这个客户端会一直存在, 直到服务器关闭 载入 AOF 文件时使用的伪客户端在载入工作开始时动态创建, 载入工作完毕之后关闭 6. 服务器 一个命令请求从发送到完成主要包括以下几个步骤: 1) 客户端将命令请求发送给服务器; 2) 服务器读取命令请求; 3） 命令执行器根据参数查找命令的实现函数; 4) 服务器将命令回复给客户端 serverCron 函数默认每隔 100ms 执行一次, 它的主要工作包括更新服务器状态信息, 处理服务器接收的 SIGTERM 信号, 管理客户端资源和数据库状态, 检查并执行持久化操作 服务器从启动到能够处理客户端的命令请求需要执行以下步骤: 1) 初始化服务器状态; 2) 载入服务器配置; 3) 初始化服务器数据结构; 4) 还原数据库状态; 5) 执行事件循环","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"Java基础知识索引","slug":"Java基础知识索引","date":"2018-03-28T03:46:16.000Z","updated":"2018-03-29T06:46:05.607Z","comments":true,"path":"2018/03/28/Java基础知识索引/","link":"","permalink":"https://aaronshi32.github.io/2018/03/28/Java基础知识索引/","excerpt":"","text":"Java基础知识索引记录在日常工作中看到的一些浅显易懂的精华帖 ClassLoader 双亲委派模型, 隔离性 https://www.cnblogs.com/wxd0108/p/6681618.html CNAME, A, 重定向的区别 A记录 —— 映射域名到一个或多个IP, 适应于独立主机、有固定IP地址CNAME——映射域名到另一个域名（子域名）, 适应于虚拟主机、变动IP地址主机URL转发——重定向一个域名到另一个URL地址，使用HTTP 301状态码, 适应于更换域名又不想抛弃老用户","categories":[],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://aaronshi32.github.io/tags/基础知识/"}],"keywords":[]},{"title":"2018书单","slug":"2018书单","date":"2018-03-28T01:27:38.000Z","updated":"2018-04-02T03:52:20.523Z","comments":true,"path":"2018/03/28/2018书单/","link":"","permalink":"https://aaronshi32.github.io/2018/03/28/2018书单/","excerpt":"","text":"思想类 《激荡十年，水大鱼大》 吴晓波 小说类技术类 《Redis 设计与现实》 黄健宏","categories":[],"tags":[{"name":"日常","slug":"日常","permalink":"https://aaronshi32.github.io/tags/日常/"},{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-Redis 数据结构与对象","slug":"读书笔记-Redis 数据结构与对象","date":"2018-02-02T02:49:06.000Z","updated":"2018-04-02T05:55:13.180Z","comments":true,"path":"2018/02/02/读书笔记-Redis 数据结构与对象/","link":"","permalink":"https://aaronshi32.github.io/2018/02/02/读书笔记-Redis 数据结构与对象/","excerpt":"","text":"Redis：数据结构与对象1. SDS：简单动态字符串（Simple Dynamic String）在 Redis 里面，C 语言传统的字符只会作为常量，用在一些无须修改的字符串，其他字符串都用 SDS 123456789struct sdshdr &#123; // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];&#125; SDS 与 C 字符串的区别 获取字符串长度：O(1)， len STRLEN key 命令复杂度仅为 O(1) 杜绝缓冲区溢出：buffer overflow SDSCAT（SDS API） 在拼接字符串之前会先检查空间是否足够(free)，不够的话先用 SDS 空间分配策略进行分配，再进行拼接 APPEND key 永远不会抹掉其他字符串的内存空间 减少修改字符串时带来的内存重分配次数 对于修改 C 字符串而言，拼接操作(append)会扩展底层数组的空间大小，截断操作(trim)会释放不再使用的空间，这两种内存重分配操作前者容易引起缓冲区溢出，后者容易引起内存泄漏，为了解决这两个问题，SDS 采用 空间预分配 和 惰性空间释放 两种优化策略 a. 空间预分配：当 SDS 需要修改并进行空间扩展时，程序不仅会为 SDS 分配修改所必须的空间，还会为 SDS 分配额外的未使用空间(free) a.1 分配后 len &gt; 1M，则给 free 预分配 1M 空间 a.2 分配后 len &lt; 1M，则给 free 预分配 len 空间 通过这种预分配策略，SDS 将连续增长 N 次字符串所需要的内存重分配次数从必定 N 次降低为 最多 N 次 b. 惰性空间释放：当 SDS 需要缩短保存的字符串时，程序不会立即回收多出来的字节，而是使用 free 属性将这些字节数量记录起来，等待再次使用 二进制安全 buf 长度是 len，决定了结尾，即使 buf 中存在 ‘\\0’，也不会被认为是结束 兼容部分 C 字符串函数 strcasecmp(sds-&gt;buf，”hello world”) strcat(c_string，sds-&gt;buf) 2. LinkedList：链表在 Redis 中，链表建的操作，底层实现之一的数据结构就是链表，除此之外，发布与订阅、慢查询、监视器等功能也用的是链表 链表节点（listNode）： 123456789101112typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点值 void *value;&#125; listNode; 链表（list）： 123456789101112131415161718192021typedef struct list &#123; // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 链表所包含的节点数 unsigned long len; // 节点值复制函数 void *(*dup) (void *ptr); // 节点值释放函数 void (*free) (void *ptr); // 节点值对比函数 int (*match) (void *ptr);&#125; list; Redis 使用 list 结构持有链表，是 双端、无环、带表头指针和表尾指针，带链表长度计数器、多态（void * 接收各种类型的值） 性质的链表 3. Map：字典在 Redis 中，字典是哈希键的底层实现之一，字典由哈希表实现，哈希表由哈希表节点实现，哈希表节点就是键值对 哈希表节点 12345678910111213141516typedef struct dictEntry&#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个了哈希表节点，形成链表：解决哈希冲突 struct dictEntry *next;&#125; dictEntry; 哈希表 123456789101112131415typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算哈希值：等于 size - 1 unsigned long sizemask; // 已有节点数量 unsigned long used; &#125; dictht; 字典 123456789101112131415typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表：每个字典由两个哈希表，一个平时使用，一个仅在 rehash 时使用 dictht ht[2]; // rehash索引 int trehashidx;&#125; dict; 其中，type 和 privdata 是针对不同类型的键值对，为创建多态字典而设置，type 是指向 dictType 结构的指针，每个结构保存了一簇用于操作特定类型键值对的函数，比如：不同类型的哈希函数 ht 属性是一个包含两个项的数组，一般情况下，字典只使用 ht[0] 哈希表，ht[1] 当进行 rehash 时使用 Redis 的哈希算法使用的是 MurmurHash hash = dict -&gt; type -&gt; hashFunction(key) index = hash &amp; dict -&gt; ht[x].sizemask Redis 使用链表地址发来解决冲突，新节点将插入链表表头（O(1)） 重新哈希（rehash）操作对哈希表的大小进行相应的扩展或者收缩，维持负载因子（load factor）在一个合理的范围之内，实际上就是 ht[0] 和 ht[1] 相互替代（比如：扩展 ht[1] - 迁移 0-&gt;1 - 释放 ht[0]） load factor = ht[0].used / ht[0].size 哈希表的扩展与收缩的时机 服务器目前没有执行 BGSAVE 或者 BGREWRITEAOF 命令，并且哈希表的负载因子 &gt;= 1; 服务器目前正在执行 BGSAVE 或者 BGREWRITEAOF 命令，并且哈希表的负载因子 &gt;= 5; 渐进 rehash：为了避免 rehash 对服务器性能造成影响，服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1]，而是分多次、渐进式的将 ht[0] 里面的键值对慢慢 rehash 到 ht[1]，采用分治的思想，随着操作，随着 rehash，期间新加入的值会直接进入 ht[1]，如果 ht[0] 中 get 不到，会自动去 ht[1] 里面查找 4. Skip List：跳表 跳跃表是有序集合的底层实现之一 Redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成, 其中 zskiplist 用于保存跳跃表信息（比如表头、表尾节点、长度）, 而 zskiplistNode 则用于表示跳跃表节点 每个跳跃表节点的层高都是 1 至 32 之间的随机数 在同一个跳跃表中, 多个节点可以包含相同的分值, 但每个节点的成员对象必须是唯一的 跳跃表中的节点按照分值大小进行排序, 当分值相同时, 节点按照成员对象的大小进行排序 5. IntSet: 整数集合123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; 每次加入新的元素，都有可能引发升级: 1. 扩展空间, 2: 类型统一化, 3: 将新元素和老元素统一加入到扩展后的空间, 需要注意的是: 不支持降级 整数集合是集合键的底层实现之一 整数集合的底层实现为数组, 这个数组以有序、无重复的方式保存集合元素, 在有需要时, 程序会根据新添加元素的类型, 改变这个数组的类型 升级操作为整数集合带来了操作上的灵活性, 并且尽可能的节约了内存 整数集合只支持升级操作, 不支持降级操作 6. Zip List: 压缩列表 压缩列表是一种为节约内存而开发的顺序型数据结构 压缩列表被用作列表键和哈希键的底层实现之一 压缩列表可以包含多个节点, 每个节点可以保存一个字节数组或者整数值 添加新节点到压缩列表, 或者从压缩列表中删除节点, 可能会引发连锁更新操作, 但这种操作出现的几率并不高 7. Object: 对象Redis 并没有直接使用这些数据结构来实现键值对数据库, 而是基于这些数据结构创建了一个对象系统, 这个系统包含 字符串对象、列表对象、哈希对象、集合对象和有序集合对象 五种, 根据命令, 判断哪种对象适合就用于执行 Redis 数据库中的每个键值对的键和值都是一个对象 Redis 共有字符串、列表、哈希、集合、有序集合五种类型的对象, 每种类型的对象至少都要两种或以上的编码方式, 不同的编码可以在不同的使用场景上优化对象的使用效率 服务器在执行某些命令之前, 会先检查给定键的类型能否执行指定的命令, 而检查一个键的类型就是检查键的值对象的类型 Redis 的对象系统带有引用计数实现的内存回收机制 Redis 会共享值为 0 到 9999 的字符串对象 对象会记录自己的最后一次被访问的时间, 这个时间可以用于计算对象的空转时间","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"加密算法","slug":"加密算法","date":"2018-01-16T06:02:03.000Z","updated":"2018-04-03T03:34:08.634Z","comments":true,"path":"2018/01/16/加密算法/","link":"","permalink":"https://aaronshi32.github.io/2018/01/16/加密算法/","excerpt":"","text":"工作中需要使用一种加密算法，来验证消息的来源，故借此了解下这个专题 常见的加密算法可以分为三类：对称加密，非对称加密，哈希 首先是对称加密，即加密和解密使用相同的秘钥（K），优势在于速度快，当 K 很长时候，破解难度异常大，缺点是加密通路有 N 条，比如 Encrypt（A，B）和 Encrypt（B，A）是两条加密通路，则需要 N 个秘钥，其中 A，B 分别获有自己的和对方的秘钥，这就带来了秘钥泄露的风险，如果多个通路公用一个秘钥的话，一旦泄露，保密性也就无从谈起 常见的加密算法有：AES，DES，3DES，Blowfish，IDEA，RC4，RC5，RC6 接下来是非对称加密，即加密和解密使用不同的秘钥（K，K’），又称为公钥和私钥，使用公钥进行加密，使用私钥进行解密，优势在于私钥是唯一的，其他用户除了可以可以通过信息发送者的公钥来验证信息的来源是否真实，还可以确保发送者无法否认曾发送过该信息，缺点在于速度慢 常见的非对称加密算法有：RSA，ECC，DSA，Diffie-Hellman，EI Gamal 最后是哈希算法，它是一种单向的算法，即可以将目标信息通过 Hash 算法生成具有一定长度的 Hash 值，却不能通过这个 Hash 值从新获得目标信息，因此常用于不可还原的密码存储，信息完整性校验等 常见的哈希算法有： MD5，SHA，MD2，MD4，HAVAL 由于项目的本身需要，加密端在 PC，解密端在移动设备，且需要根据加密消息进行相关有效性验证，故最终选择 ECC 算法来","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"基础知识-HashMap实现与原理","slug":"基础知识-HashMap实现与原理","date":"2017-12-25T08:42:04.000Z","updated":"2017-12-30T02:33:20.000Z","comments":true,"path":"2017/12/25/基础知识-HashMap实现与原理/","link":"","permalink":"https://aaronshi32.github.io/2017/12/25/基础知识-HashMap实现与原理/","excerpt":"","text":"哈希表又称为散列表（HashTable），应用场景诸如缓存技术（memcached），xxx 等 几种数据机构在新增，查找等基础操作的执行性能 数组，指定下标查找 O(1)，指定值查找 O(n)（有序的情况下二分，插值可以达到 O(logn)），新增 O(n) 线性链表，查找 O(n)，新增 O(1) 二叉树，对一棵相对平衡的有序二叉树，新增和查找操作平均 O(logn) 哈希表，不考虑哈希冲突的情况下，新增和查找平均为 O(1) 哈希表的实质：数组 A + 哈希函数 + 解决哈希冲突的方案 而对于数组的下表，即元素的存储位置是通过哈希函数计算出来的，这个哈希函数就是 f，有以下公式 存储位置 = f(关键字)，f 为哈希函数 哈希表的一切操作前提是通过这个哈希函数，找到元素的存储位置，继而进行操作，可在找存储位置的时候，一旦发现已经先有元素占用了，这就引发了哈希冲突问题 哈希冲突： f(i) = f(j)，i ≠ j 没有完美的哈希函数存在，好的哈希函数会尽可能地保证 计算简单 和 散列地址分布均匀，一旦冲突发生，有以下解决方案： 开放定址法（发生冲突，继续寻找下一块未被占用的存储地址）， 二次散列函数法 链地址法（HashMap）也就是数组+链表的方式 HashMap 实现原理：数组 + 链表数组 1234567891011121314151617181920212223242526272829303132333435363738static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; HashMap 其实就是一个 以上 Entry 数组，Entry 对象中包含了键和值，其中 next 也是一个 Entry 对象，它就是用来处理 hash 冲突的，形成一个链表 几个重要的因素 12345678//实际存储的key-value键值对的个数transient int size;//阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。HashMap在进行扩容时需要参考threshold，后面会详细谈到int threshold;//负载因子，代表了table的填充度有多少，默认是0.75final float loadFactor;//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount; 哈希函数 123456789101112//这是一个神奇的函数，用了很多的异或，移位等运算，对key的hashcode进一步进行计算以及二进制位的调整等来保证最终获取的存储位置尽量分布均匀final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 注意： 重写 equals 方法需同时重写 hashCode 方法，因为 HashMap 是通过 hashCode 进行映射的，如果不重写则映射不到 value putIfAbsent 是线程安全的，这个方法等价于在key不存在的时候加入一个值，如果key存在就不放入，记得判断返回值","categories":[],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://aaronshi32.github.io/tags/基础知识/"}],"keywords":[]},{"title":"基础知识-Java 语法","slug":"基础知识-Java语法","date":"2017-12-11T12:11:30.000Z","updated":"2018-01-12T02:23:32.000Z","comments":true,"path":"2017/12/11/基础知识-Java语法/","link":"","permalink":"https://aaronshi32.github.io/2017/12/11/基础知识-Java语法/","excerpt":"","text":"Q：Transient 作用 A：1）一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问 2）transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口 3）一个静态变量不管是否被transient修饰，均不能被序列化 4）若实现的是Externalizable接口，则没有任何东西可以自动序列化，需要在writeExternal方法中进行手工指定所要序列化的变量，这与是否被transient修饰无关 Q：接口和抽象类的区别 A：抽象类： 1）抽象方法必须为public或者protected（因为如果为private，则不能被子类继承，子类便无法实现该方法），缺省情况下默认为public。 2）抽象类不能用来创建对象； 3）如果一个类继承于一个抽象类，则子类必须实现父类的抽象方法。如果子类没有实现父类的抽象方法，则必须将子类也定义为为abstract类 接口： 1）接口中的变量会被隐式地指定为public static final变量 2）方法会被隐式地指定为public abstract方法且只能是public abstract方法 继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系，一个类只能继承一个抽象类，而一个类却可以实现多个接口 Q：serialVersionUID 作用 A：Java 的序列化机制是通过在运行时判断类的 serialVersionUID 来验证版本一致性的。在进行反序列化时，JVM 会把传来的字节流中的serialVersionUID 与本地相应实体（类）的 serialVersionUID 进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常。(InvalidCastException) 1）两端不一致，无法序列化 2）两端一致，增的字段会序列化成默认值 3）两端一致，减的字段会序列化丢失 Q：多线程相关 A： 1） 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时；并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时 2）线程安全：代码在多线程中使用，线程的调度顺序不影响结果 3）线程状态：NEW，RUNNABLE，WAITING，BLOCKED，TERMINATED，TIMED_WAITING 4）sleep 和 wait 区别：前者不会释放锁，后者会 5）三种线程实现方式：Thread，Runnable，Callable（Future），后者可以返回线程执行结果 6）容器类：BlockingQueue、ConcurrentHashMap 7）ConcurrentHashMap 是用 lock 实现并发（锁的方式是稍微细粒度的。将hash表分为16个桶（默认值），诸如get, put, remove等常用操作只锁当前需要用到的桶）而 HashTable 是用 synchronized 实现并发（对整个集合加锁，加锁期间集合不可访问） Q：String 类是不可变的吗 A：从语法上来讲，是的，因为 String 类是用 final 修饰的，绝对吗？不绝对，因为可以用 UnSafe 来修改 String 值；多个相同值的 String，可以用 intern（） 来返回存储在字符串池的值，需要注意：采用new 创建的字符串对象不进入字符串池，见以下代码 1234567891011String str1 = \"a\"; String str2 = \"b\"; String str3 = \"ab\"; String str4 = str1 + str2; String str5 = new String(\"ab\"); System.out.println(str5.equals(str3)); // true System.out.println(str5 == str3); // false System.out.println(str5.intern() == str3); // true: str3 是直接声明的，进入字符串池 System.out.println(str5.intern() == str4); // false: str5 是 new 声明的，不进入字符串池","categories":[],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://aaronshi32.github.io/tags/基础知识/"}],"keywords":[]},{"title":"基础知识-Http 和 Https","slug":"基础知识-Http 和 Https","date":"2017-11-25T08:42:04.000Z","updated":"2017-12-30T06:31:52.000Z","comments":true,"path":"2017/11/25/基础知识-Http 和 Https/","link":"","permalink":"https://aaronshi32.github.io/2017/11/25/基础知识-Http 和 Https/","excerpt":"","text":"TCP 三次握手 和 四次挥手三次握手 Client 发送 SYN 给 Server，Client 状态置为 SYN-SEND Server 发送 SYN + ACK 给 Client，Server 状态置为 SYN-RCVD Client 发送 ACK 给 Server，Server 状态置为 ESTABLISED 四次挥手 Client 发送 FIN 给 Server，Client 状态置为 FIN-WAIT-1 Server 发送 ACK 给 Client，Server 状态置为 CLOSE-WAIT，Client 收到后置为 FIN-WAIT2 Server 发送 FIN 给 Client，Sever 状态置为 LAST-ACK Client 发送 ACK 给 Server，Client 状态置为 TIME-WAIT，Server 收到后状态置为 CLOSE Http 和 HttpsHTTP是应用层协议，位于HTTP协议之下是传输协议TCP。TCP负责传输，HTTP则定义了数据如何进行包装 HTTP - TCP（明文传输） HTTPS - TLS/SSL - TCP（密文传输）","categories":[],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://aaronshi32.github.io/tags/基础知识/"}],"keywords":[]},{"title":"SpringBoot 问题汇总","slug":"SpringBoot 问题汇总","date":"2017-10-16T03:22:52.000Z","updated":"2017-10-19T09:48:32.000Z","comments":true,"path":"2017/10/16/SpringBoot 问题汇总/","link":"","permalink":"https://aaronshi32.github.io/2017/10/16/SpringBoot 问题汇总/","excerpt":"","text":"简介最近上手项目, 开始接触了 SpringBoot, 相比较 SpringMVC 而言, 省去了繁琐的配置, 秉承默认大于配置的原则, 使用起来更加简单方便。但越是黑盒(简单), 使用起来越不安, 这里将学习过程中遇到的问题记录下来, 慢慢地打开这个黑盒 初始化工程问题 使用 Maven 初始化, 有两种方式, 以此解决 Maven 不支持多 parent 的问题 继承默认的 parent 123456&lt;!-- Inherit defaults from Spring Boot --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;&lt;/parent&gt; - 将 SpringBoot 的依赖添加到 dependencyManagement 中，并且设置 scope=import 1234567891011121314151617181920&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Override Spring Data release train provided by Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-releasetrain&lt;/artifactId&gt; &lt;version&gt;Fowler-SR2&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;!-- Spring Boot basic dependencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 2. Maven用户可以继承 spring-boot-starter-parent 项目来获取合适的默认设置。该parent项目提供以下特性 12345678- 默认编译级别为Java 1.6- 源码编码为 UTF-8- 一个 dependency management 节点，允许你省略常见依赖的 &lt;version&gt; 标签，继承自 spring-boot-dependencies POM。- 恰到好处的资源过滤- 恰到好处的插件配置（exec插件，surefire，Git commit ID，shade）- 恰到好处的对 application.properties 和 application.yml 进行筛选，- 包括特定 profile（profile-specific）的文件，比如 applicationfoo.- properties 和 application-foo.yml 3. Spring Boot Starters 列表 官方：https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-starter 中文：http://blog.csdn.net/chszs/article/details/50610474 4. 配置工程自检功能：`spring-boot-starter-actuator` 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件中增加：management.security.enabled=false 访问以下网站： 123456http://localhost:8080/beanshttp://localhost:8080/envhttp://localhost:8080/healthhttp://localhost:8080/metricshttp://localhost:8080/tracehttp://localhost:8080/mappings 默认 的奥秘，来源于：spring-boot-autoconfigure 的 JAR 文件 @SpringBootApplication 注解等价于以默认属性使用 @Configuration ， @EnableAutoConfiguration 和 @ComponentScan，即开启组件扫描和自动配置 application.properties（yml） 默认加载路径：当前目录下 /config 子目录，当前目录，classpath 下的 /config，classpath 根路径。如果不喜欢将 application.properties 作为配置文件名，你可以通过指定 spring.config.name 环境属性来切换其他的名称，也可以使用spring.config.location 环境属性引用一个明确的路径（目录位置或文件路径列表以逗号分割） Spring 4.0 的条件化配置是自动配置的基础，当满足一定条件时才会执行某段程序，比如在 classpath 中发现了 JdbcTemplate 时才自动注入，这使得众多 autoconfig 选项得以简化 配置的加载顺序 Spring Boot设计了一个非常特别的 PropertySource 顺序，以允许对属性值进行合理的覆盖，属性会以如下的顺序进行设值： home目录下的devtools全局设置属性（ ~/.spring-bootdevtools.properties ，如果devtools激活） 测试用例上的@TestPropertySource注解 测试用例上的@SpringBootTest#properties注解 命令行参数 来自 SPRING_APPLICATION_JSON 的属性（环境变量或系统属性中内嵌的内联JSON） ServletConfig 初始化参数 ServletContext 初始化参数 来自于 java:comp/env 的JNDI属性 Java系统属性（System.getProperties()） 操作系统环境变量 RandomValuePropertySource，只包含 random.* 中的属性 没有打进jar包的Profile-specific应用属性（ application-{profile}.properties 和YAML变量） 打进jar包中的Profile-specific应用属性（ application-{profile}.properties 和YAML变量） 没有打进jar包的应用配置（ application.properties 和YAML变量） 打进jar包中的应用配置（ application.properties 和YAML变量） @Configuration 类上的 @PropertySource 注解 默认属性（使用 SpringApplication.setDefaultProperties 指定） 开发调试问题 使用 spring-boot-devtools 来实现热部署（TODO） Maven 构建插件的主要功能是把项目打包成一个可执行的超级 JAR（uber-JAR），包括把应用程序的所有依赖打入 JAR 文件内，并为 JAR 添加一个描述文件，其中的内容能够通过 java -jar 来运行应用程序 Spring 启动问题 精辟：读取配置说明（xml，java配置，Groovy配置，其他类型配置），再应用程序上下文里初始化 Bean，将 Bean 注入依赖他们的其他 Bean 中，Spring 帮你通过 组件扫描，自动织入和生命切面等额外辅助功能，帮你简单的做了初始化的事情 导入的 starter 是如何 在 application.properties 中给出配置提示的 starter 的包 /META-INF/spring.factories 中会有 org.springframework.boot.autoconfigure.EnableAutoConfiguration 自动配置的实现类，打开这个类可以看到实现了 ImportBeanDefinitionRegistrar 接口的 registerBeanDefinitions 方法，如此一来，配置文件中就会给出提示啦","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"https://aaronshi32.github.io/tags/框架/"}],"keywords":[]},{"title":"NodeJS - 理解 内存控制","slug":"NodeJS - 理解 内存控制","date":"2017-08-29T03:22:52.000Z","updated":"2017-08-29T03:32:24.000Z","comments":true,"path":"2017/08/29/NodeJS - 理解 内存控制/","link":"","permalink":"https://aaronshi32.github.io/2017/08/29/NodeJS - 理解 内存控制/","excerpt":"","text":"简介V8 具有内存限制，所有的 JavaScript 对象都是通过堆来进行分配的，可以通过 process.memoryUsage() 来查看内存信息，其中 heapTotal 和 heapUsed 分别代表了已申请到的对内存和当前使用的量。如果当前代码已申请的堆空闲内存不够分配新的对象，将就申请堆内存，知道堆的大小超过 V8 的内存限制为止 为何采取 V8 内存限制：一次小的垃圾回收需要 50ms 以上，一次非增量式的垃圾回收甚至需要 1s 以上，这是垃圾回收引起的 JS 线程暂停执行的时间，应用的性能和响应时间都会大幅度下降 V8 的垃圾回收机制采用 node –trace-gc xxx 命令行参数来查看内存垃圾回收日志，使用 –prof 可以得到 V8 执行时的性能分析数据，配合 tick-processor 工具查看统计信息 垃圾回收算法 基于分代式垃圾回收（解决不同的对象生命周期不同） --max-old-space-size 指定老生代内存空间的最大值 + --max-new-space-size 指定新生代内存空间的最大值 = V8 堆的整体大小 新生代的回收算法：Scavenge（base on Cheney） 核心思想：空间一分为二，从 From 空间 复制 到 To 空间，缺点是只能使用堆内存的一般，好处是以空间换取时间（块），适合新生代频繁的内存回收 对象晋升两个条件：是否经历过 Scavenge 回收，To空间的内存占用是否超过了比例（25%） 老生代的回收算法：Mark-Sweep &amp; Mark-Compact 核心思想：标记 - 清楚 - 整理内存碎片 回收策略：延迟清理（lazy sweeping）和 增量式整理（incremental compaction） 为了降低全堆垃圾回收带来的线程停顿问题，采用增量标记来减少由于垃圾回收造成的停顿时间 高效使用内存在正常的 JavaScript 执行中，无法立即回收的内存有必报和全局变量引用这两种情况，由于 V8 的内存限制，要十分小心此类变量是否无限制的增加，因为他会导致老生代的对象增多 内存指标 使用 process.memoryUsage() 查看 Node 进程的内存占用情况 12345678910111213141516171819202122232425// outofmemory.jsfunction showMem()&#123; var mem = process.memoryUsage(); var format = function(bytes)&#123; return (bytes / 1024 / 1024).toFixed(2) + 'MB'; &#125; console.log(`Process: heapTotal $&#123;format(mem.heapTotal)&#125; heapUsed $&#123;format(mem.heapUsed)&#125; rss $&#123;mem.rss&#125;`)；&#125;var useMem = function()&#123; var size = 20 * 1024 * 1024; var arr = new Array(size); for(var i = 0; i &lt; size; i++)&#123; arr[i] = 0; &#125; return arr;&#125;var total = [];for(var j = 0; j &lt; 15； j++)&#123; showMem(); total.push(useMem());&#125;showMem(); 使用 os.totalmem() 和 os.freemem() 查看 操作系统 的内存情况 堆外内存：那些不是通过 V8 分配的内存 - Buffer 对象","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"NodeJS - 理解 Buffer","slug":"NodeJS - 理解 Buffer","date":"2017-08-29T03:22:52.000Z","updated":"2017-08-29T03:31:12.000Z","comments":true,"path":"2017/08/29/NodeJS - 理解 Buffer/","link":"","permalink":"https://aaronshi32.github.io/2017/08/29/NodeJS - 理解 Buffer/","excerpt":"","text":"简介Buffer 是一个像 Array 的对象，主要用于操作字节，数组元素为 16 进制的两位数，即 0 到 255的数值，如果超出或者不足，小数等情况，会使用叠加，递减，省略小数部分的措施保证元素数值合法性，此外，采用 JavaScript 和 C++ 相结合的模式，将性能部分用 C++ 来实现，非性能相关的部分用 JavaScript 来实现 内存分配机制Buffer 对象的内存分配不是在 V8 的堆内存中，而是在 Node 的 C++ 层面实现内存的申请，采用 slab 动态内存管理机制（先申请，后分配），以 4KB 作为界限来区分 Buffer 是大对象还是小对象，针对大对象，每次都 alloc 一个足够长的 SlowBuffer 对象（C++层）作为 slab 单元，针对小对象，则共用一个 slab，当不足以分配时（可分配小于 4KB），才会 alloc 一个新的 slab 内存进行再分配。需要注意的是当且仅当一个 slab 上面的所有小对象在作用域释放并都可以回收时，slab 的 8KB 才会被回收，此处会存在由于编码不当导致的内存泄漏，浪费问题 在 Buffer 中创建一个数组，需要注意以下规则： Buffer 是内存拷贝，而不是内存共享 Buffer 占用内存被解释为一个数组，而不是字节数组。比如，new Uint32Array(new Buffer([1,2,3,4])) 创建了 4 个 Uint32Array，它的成员为 [1,2,3,4]，而不是 [0x1020304] 或 [0x4030201] 1234567891011121314151617// 4KB 作为界限的由来：createPool 判断条件Buffer.poolSize = 8 * 1024; function allocate(size) &#123; if (size &lt;= 0) &#123; return new FastBuffer(); &#125; if (size &lt; (Buffer.poolSize &gt;&gt;&gt; 1)) &#123; if (size &gt; (poolSize - poolOffset)) createPool(); var b = new FastBuffer(allocPool, poolOffset, size); poolOffset += size; alignPool(); return b; &#125; else &#123; return createUnsafeBuffer(size); &#125;&#125; 四种 内存分配的 API Buffer.from Buffer.alloc Buffer.allocUnSafe Buffer.allocUnSafeSlow 支持与字符串相互转换目前支持的字符串编码类型有：ASCII，UTF-8，UTF-16LE/UCS-2，Base64，Binary，Hex，可以用 isEncoding() 来判断是否支持编码 对于不支持的编码类型，可以通过 iconv 和 iconv-lite 两个模块来支持更多编码类型转换 转换成 Buffer：new Buffer(str，[encoding]) 和 buf.write(string，[offset]，[length]，[encoding]) 转换成 String：buf.toString([encoding]，[start]，[end]) 正确的拼接方式用一个数组来存储接收到的所有 Buffer 片段并记录下所有片段的总长度，然后调用 Buffer.concat() 方法生成一个合并的 Buffer 对象 123456789101112131415161718192021222324252627282930313233343536Buffer.concat = function concat(list, length) &#123; var i; if (!Array.isArray(list)) throw kConcatErr; if (list.length === 0) return new FastBuffer(); if (length === undefined) &#123; length = 0; for (i = 0; i &lt; list.length; i++) length += list[i].length; &#125; else &#123; length = length &gt;&gt;&gt; 0; &#125; var buffer = Buffer.allocUnsafe(length); var pos = 0; for (i = 0; i &lt; list.length; i++) &#123; var buf = list[i]; if (!isUint8Array(buf)) throw kConcatErr; _copy(buf, buffer, pos); pos += buf.length; &#125; // Note: `length` is always equal to `buffer.length` at this point if (pos &lt; length) &#123; // Zero-fill the remaining bytes if the specified `length` was more than // the actual total length, i.e. if we have some remaining allocated bytes // there were not initialized. buffer.fill(0, pos, length); &#125; return buffer;&#125;; Buffer 与性能 网络传输用 Buffer 比直接传字符串要快很多 通过预先转换静态内容为 Buffer 对象，可以有效地减少 CPU 的重复使用，节省服务器资源。在构建 Web 应用中，可以选择将页面中的动态内容和静态内容分离，静态内容部分可以通过预先转换为 Buffer 的方式，是性能得到提升。由于文件自身是二进制数据，所以在不需要改变内容的场景下，尽量只读取 Buffer，然后直接传输，不做额外的转换，避免损耗 文件读取速度与 highWaterMark 有关 这个值代表了每次读取的长度，对 Buffer 内存的分配和使用有一定影响，设置过小，可能导致系统调用的次数过多，在读取一个相同的大文件时，该值越大，读取的速度越快","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（十一）","slug":"读书笔记-程序员的自我修养（十一）","date":"2017-07-05T02:51:46.000Z","updated":"2017-07-05T02:53:28.000Z","comments":true,"path":"2017/07/05/读书笔记-程序员的自我修养（十一）/","link":"","permalink":"https://aaronshi32.github.io/2017/07/05/读书笔记-程序员的自我修养（十一）/","excerpt":"","text":"系统调用与API 普及：现代操作系统中程序本身是 没有权利访问过多系统资源 的，为了防止程序访问冲突，操作系统将可能产生冲突的系统资源给 保护起来 普及：每个操作系统都会提供 一套接口，以供应用程序使用，这些接口往往通过 中断 来实现，比如 Linux 使用 0x80 号中断作为系统调用的入口，Windows 采用 0x2E 号中断作为系统调用入口 系统调用的弊端 使用不便，操作系统提供的系统调用接口往往过于原始，程序员需要了解很多与操作系统相关的细节 各个操作系统之间系统调用不兼容，定义和实现都不大一样 为此：运行时库将不同的操作系统的系统调用包装为统一固定的接口，使得童颜的代码，在不同的操作系统下都可以直接编译，并产生一致的效果，这就是源码级上的可移植性 系统调用的原理 用户态 和 内核态：现代操作系统的CPU在不同特权级别下执行不同的指令，称之为 用户模式（User Mode） 和 内核模式（Kernel Mode） 系统调用 是运行在内核态的，而 应用程序 基本都是运行在用户态的 操作系统一般通过 中断 来从用户态 切换 到内核态，中断是一个硬件或软件发出的 请求，要求 CPU 暂停当前的工作 转手去处理 更加重要的事情 中断的两个属性：中断号（Interrupt Number）（中断类型） 和 中断处理程序（Interrupt Service Routine）（既然中断了就要告诉CPU去干什么） 中断向量表（Interrupt Vector Table）：是个数组，第 n 项包含了指向第 n 号中断的中断处理程序的 指针 中断的流程：当中断到来时，CPU 会暂停当前执行的代码，根据中断号，在中断向量表中找到对应的中断处理程序，并调用它。中断处理程序执行完成之后，CPU 会继续执行之前的代码 硬件中断 和 软件中断：硬件中断通常来源于硬件的异常或其他事情的发生，软件中断通常是一条 指令（i386 下是 int），带有一个参数记录中断号，使用这条指令用户可以手动触发某个中断并执行其终端处理程序，比如 int 0x80 会调用第 0x80 号中断的处理程序 Windows API Windows API 是以 DLL 导出函数的形式暴露给应用开发者的，规模上非常庞大，其中一个头文件 “Windows.h” 包含了核心部分 基本服务：kernel32.dll、图形设备接口：gdi32.dll、用户接口：user32.dll、高级服务：advapi32.dll、通用对话框：comdlg32.dll、通用控件：comctl32.dll、Shell：shell32.dll、网络服务：ws2_32.dll","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（十）","slug":"读书笔记-程序员的自我修养（十）","date":"2017-06-26T03:03:20.000Z","updated":"2017-06-26T03:07:18.000Z","comments":true,"path":"2017/06/26/读书笔记-程序员的自我修养（十）/","link":"","permalink":"https://aaronshi32.github.io/2017/06/26/读书笔记-程序员的自我修养（十）/","excerpt":"","text":"运行库 入口函数和程序初始化 普及：操作系统装载程序之后，首先运行的代码并不是 main 的第一行，而是 某些别的代码，这写代码负责准备好 main 函数执行所需要的环境，并且负责调用 main 函数，我们称这写代码为 入口函数 或 入口点（Entry Point） 程序初始化：Main函数之前有个入口函数 操作系统在创建进程后，把控制权交到了程序的入口，这个入口往往是运行库中的某个入口函数 入口函数对运行库和程序运行环境进行初始化，包括堆、I/O、线程、全局变量构造等 入口函数在完成初始化之后，调用 main 函数，正式开始执行程序主体部分 main 函数执行完毕以后，返回到入口函数，入口函数进行清理工作，然后进行系统调用结束进程 入口函数示例 GLIBC（Linux）：__start -&gt; __libc_start_main -&gt; exit -&gt; _exit，即在 __libc_start_main 执行之前，做了参数压入栈，寄存器初始化，全局变量赋值等操作 MSVC CRT（Windows）：初始化和 OS 版本有关的全局变量，初始化堆，初始化 I/O，获取命令行参数和环境变量，初始化C库的一些数据，调用 main 并记录返回值，检查错误并将 main 的返回值返回 堆 初始化：mainCRTStartup –&gt; heap_init() –&gt; HeapCreate 方法 I/O 初始化：建立 打开文件表，如果能够继承自父进程，那么从父进程 获取 继承的句柄，初始化 标准输入输出 运行库与 I/O 对于程序来说，I/O 涵盖的范围还要广一些，一个程序的 I/O 指代了程序与外界的交互，包括文件、管道、网络、命令行、信号等 I/O 初始化函数需要在用户空间中建立 stdin、stdout、stderr 及其 对应的 FILE 结构，是的程序进入 main 之后可以直接使用 printf，scanf 等函数 C++运行库 普及：任何一个 C 程序，它的背后都有一套庞大的代码来进行支撑，以使得该程序能够正常运行。这套代码至少包括入口函数，及其所以来的函数所构成的函数集合，当然，他还理应包括各种标砖函数的实现，我们称之为 运行时库（Runtime Library），亦或 C运行库（CRT） CRT大致包含了如下功能： 启动与退出：包括入口函数及入口函数所依赖的其他函数等 标准函数：由C语言标准规定的 C语言标准库 所拥有的函数实现 I/O：I/O功能的封装和实现 堆：堆的封装和实现 语言实现：语言中一些特殊功能的实现 调试：实现调试功能的代码 C语言标准库由 24 个 C头文件 组成：标准输入输出（stdio.h），文件操作（stdio.h），字符操作（ctype.h），字符串操作（string.h），数学函数（math.h），资源管理（stdlib.h），格式转换（stdlib.h），时间/日期（time.h），断言（assert.h），各种类型上的常熟（limits.h &amp; float.h），变长参数（stdarg.h），非局部跳转（setjump.h） 运行库是和平台（操作系统）强相关 的，提供了不同操作系统平台的底层抽象，Linux 和 Window 平台下的两个主要 C 语言运行库分别为： glibc （GNC C Library） 和 MSVCRT（Microsoft Visual C Run-time） 运行库与多线程 Window API ：CreateThread() 和 ExitThread() MSVCRT：_beginThread() / _beginthreadex 和 _endthread() Glibc：pthread_create() 和 pthread_exit()","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（九）","slug":"读书笔记-程序员的自我修养（九）","date":"2017-06-20T02:06:20.000Z","updated":"2017-06-20T02:08:04.000Z","comments":true,"path":"2017/06/20/读书笔记-程序员的自我修养（九）/","link":"","permalink":"https://aaronshi32.github.io/2017/06/20/读书笔记-程序员的自我修养（九）/","excerpt":"","text":"内存：一个承载程序运行的介质，也是程序进行各种运算和表达的场所 程序的内存（进程的地址空间）布局 栈：用于维护函数调用的上下文，执行 函数调用 的功能 堆：用于程序 动态分配 的内存区域，也是 malloc 或 new 分配的内存区域 可执行文件映像：存储着可执行文件在内存里的映像，装载器 保留区：保留区并不是一个单一的内存区域，而是对内存中受到保护而禁止访问的内存区域的总称，比如有些地址不允许访问等等 栈与调用惯例 作用：保存了一个函数调用所需要的 维护信息（函数返回地址和参数，临时变量，保存的上下文），常称为 堆栈帧（Stack Frame） 函数的调用方和被调用方对于函数如何调用，遵循 惯用惯例，包括：函数参数的传递顺序和方式，栈的维护方式，名字修饰策略。常用的管理模式有：cdecl（函数调用方），stdcall（函数本身），fastcall（函数本身），pascal（函数本身） 堆与内存管理 普及：全局变量没有办法动态地产生，只能在编译的时候定义 形象解释：运行库相当于是向操作系统 “批发” 了一块较大的对控件，然后 “零售” 给程序用。当全部 “售完” 或程序有大量的内存需求时，再根据实际需求向操作系统 “进货” Linux 提供两种系统调用：brk 和 mmap，Window 提供四种系统调用：HeapCreate，HeapAlloc，HeapFree，HeapDestroy，对向上封装的函数就是著名的 malloc 要点： 堆里的同一片内存不能重复释放两次 malloc 申请的内存，进程结束后，所有资源都会回收，因此不存在了 malloc 申请的内存，逻辑上是连贯的，物理上不一定 堆分配算法：如何管理一大块连续的内存空间，能够按照需求分配、释放其中的空间 空闲链表 核心原理：在堆里的每一个空闲空间的开头（或结尾）有一个头（header），头结构里记录了上一个（prev）和下一个（next）空间块的地址，这样所有空闲块形成了一个链表，申请的时候，查找符合大小的空闲块，然后将这块空闲空间从链表中”删除”，供使用，回收的时候，需要知道头指针和空间大小，因此在申请的时候，往往申请 K 空间，分配 K + 4 的空间，多余的 4 个记录大小，但这样一旦堆操作越界，破坏了这 4 个里面的数据，整个对就无法正常工作了 位图 将整个堆划分为大量的 块（Block），每个块大小相同，申请的时候，总是分配整数个块的空间，且称已经分配的第一块为 头（head），其余的称为 主体（Body），优点：速度快，整个堆的空闲信息存储在一个数组中，因此访问该数组时cache容易命中，稳定性好：为了避免用户越界读写破坏，只需要简单的备份下位图即可，缺点：分配容易产生碎片（平均划分），位图很大，cache命中率降低 对象池 以申请空间的大小作为分水岭，综合应用上述两种算法","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（八）","slug":"读书笔记-程序员的自我修养（八）","date":"2017-06-14T02:45:07.000Z","updated":"2017-06-14T02:46:54.000Z","comments":true,"path":"2017/06/14/读书笔记-程序员的自我修养（八）/","link":"","permalink":"https://aaronshi32.github.io/2017/06/14/读书笔记-程序员的自我修养（八）/","excerpt":"","text":"Windows 下的动态链接 普及：Windows 下的 DLL 文件和 EXE 文件实际上是一个概念，都是 PE 格式 的二进制文件，扩展名并不唯一：.dll 和 .ocx 或是 .cpl 都是 dll 文件，软件更新包（Service Packs）机制就是通过升级 DLL 的形式进行自我完善 普及：当一个 dll 被装载到内存中之后，通常有两个地址概念分别是：基地址（Base Address） 和 相对地址（RVA, Relative Virtual Address），基地址就是被装载的起始地址，RVA地址就是 地址 + 基地址 普及：dll 实现进程共享数据段，不推荐，存在一定的安全风险，应该尽量 避免 这种 dll 共享数据段来实现进程间通信 普及：声明 dll 中的某个函数为 导出函数 的办法有两种：一种是使用 __declspec(dllexport) 扩展，另一种是采用模块定义（.def）文件声明 普及：dll 支持显示运行时链接，提供了 3 个 API 分别是：LoadLibrary，GerProcAddress，FreeLibrary 符号导入导出表 导出表，EXP文件，导出重定向，导入表，导入函数调用，这些都是 dll 中存在的结构和方式，均与符号和函数相关 DLL优化 应用程序在加载 dll 导致启动速度变慢，这里主要有两个原因：1. dll 的代码段和数据段本身并不是地址无关的，当被装载的目标地址被占用时，整个 dll 便会引起 rebase，频繁的 rebase 情况更加糟糕； 2. 导入函数的符号在运行时需要被 逐个查找解析，这里用的是二分查找，整个过程随着 dll 数量的增加，也是非常耗时的 重定基地址（Rebasing）：只需要重新定位基地址即可，其余的 RVA 只是的偏移量，不受影响，当且仅当 dll 被装载时，基地址被占用的情况下，才会发生 重定位，所以 windows 系统为本身自带的许多库单独划分了一段空间区域（0x70000000 ~ 0x80000000），用于映射这些系统常用的 dll dll 绑定：把导出函数的地址保存到模块的导入表中，省去了每次启动时符号解析的过程，根本优化在于：当程序每次运行时，所有被依赖的 dll 都会装载，并且一些列的导入导出符号依赖关系都会 被重新解析，大多数情况下，这些 dll 都会 以同样的顺序 被装载到 同样的内存地址，所以他们的到处符号的地址都是不变的 在使用 C++ 时需要注意的动态链接事项 所有接口函数都应该是抽象的，所有的方法都应该是纯虚的 所有的全局函数都应该是用 extern “C” 来防止名字修饰的不兼容，并且导出函数都是应该是 __stdcall 调用规范的 不要使用 C++ 标准的 STL 不要使用异常 不要使用虚析构函数 不要在 dll 里面申请内存，而且在 dll 外释放（或者相反） 不要再接口中使用重载方法 DLL HELL：主要是更新过程中的兼容性问题，解决方法如下： 静态链接 防止 dll 覆盖（DLL Stomping） 避免 dll 冲突（Conflicting DLLs） 应用程序使用 Manifest 文件来打包，控制自身依赖的 dll","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（七）","slug":"读书笔记-程序员的自我修养（七）","date":"2017-06-06T03:03:25.000Z","updated":"2017-06-06T03:07:12.000Z","comments":true,"path":"2017/06/06/读书笔记-程序员的自我修养（七）/","link":"","permalink":"https://aaronshi32.github.io/2017/06/06/读书笔记-程序员的自我修养（七）/","excerpt":"","text":"动态链接（Dynamic Linking）：一个单一个可执行文件模块被拆分成若干模块，在程序运行时进行链接的一种方式 欲扬先抑：静态链接饱受 内存磁盘空间浪费（同一个目标文件存在多份供使用），更新发布需要重新链接 等问题，而动态链接解决了上面的问题，提供了 可扩展性（动态选择加载），但饱受 兼容性 （如不兼容，程序将崩溃无法运行），性能损耗（装载时重新链接）困扰 基本思想：把程序按照模块 拆分 成各个相对 独立 部分，在程序 运行时 才将它们链接在一起形成一个 完整 的程序，而不是像静态链接一样把所有的程序模块都链接成一个单独的可执行文件 普及： Linux 下，ELF 动态链接文件叫 动态共享对象（DSO，Dynamic Shared Objects），以 .so 结尾；Windows 下，动态链接文件叫 动态链接库（Dynamical Linking Library），以 .dll 结尾 普及：动态链接器 才完成以上操作，策略：延迟绑定（Lazy Binding） 普及：PIC（Position-independent Code）地址无关代码 技术，GOT（Global Offset Table）全局偏移量表 动态链接的地址空间分配 奥秘 共享对象的 最终装载地址 在编译时是 不确定 的，而是在 装载 时，装载器根据当前地址空间的空闲情况，动态分配一块 足够大小 的虚拟地址空间给相应的共享对象 普及：静态链接时提到的重定位叫做 链接时重定位（Link Time Relocation），而动态链接提到的重定位叫做 装载时重定位（Load Time Relocation），也成 基址重置（Rebasing） 共享对象的虚拟地址空间分配技术离不开：地址无关代码（PIC机制），共享模块的全局变量（线程私有存储 Thread Local Storage），数据段地址无关性，也正是这些无关性技术，才保证了共享对象被多个程序引用时，能够发挥各自的作用，确保程序不出现崩溃 延迟绑定（Lazy Binding）的 艺术 性能的事实：动态链接是以 牺牲性能 为代价的，具体表现在：一方面 对于全局和静态数据的访问、模块间的调用都要进行复杂的 GOT定位，然后 间接寻址，另一方面动态链接的工作是在 运行时 完成的，不是事先链接好的 优化的手段：延迟绑定，理解为当函数第一次被用到时才进行绑定（符号查找、重定位等），使用 PLT （Procedure Linkage Table） 来实现，通常以 .plt 作为段名，保存在 ELF 文件中 实现原理：通过 PLT 中的待跳转指令，将各个函数的待跳转偏移量链接到地址栏，等运行时使用的时候，直接读取偏移量进行跳转，这里不是直接读取GOT链接到真正的目标函数地址，而是读取偏移量，进行jump，再到目标函数 原话：而是将上面代码中第二条指令&quot;push n&quot;的地址填入到 bar@GOT 中，这个步骤不需要查找任何符号 动态链接 相关结构 .interp 段：保存可执行文件需要的 动态链接器 的路径，内容就是个字符串 .dymanic 段：保存了动态链接器所需要的 基本信息：依赖于哪些共享对象、动态链接符号表的位置、动态链接重定位表的位置、共享对象初始化代码的地址等，位于经典的头文件 elf.h （Elf32_Dyn） 中 动态符号表（Dynamic Symbol Table）[.dynsym 段]：只保留动态链接这些模块之间的符号导入导出关系 动态链接重定位表：.rel.dyn 是对数据引用的重定位修正，它所修正的位置位于 .got 及 数据段，.rel.plt 是对函数引用的修正，它所修正的位置位于 .rel.plt 动态链接时进程 堆栈初始化信息 堆栈里保存了关于进程 执行环境：程序执行入口 和 命令行参数 等信息，还保存了动态链接器所需要的一些 辅助信息数组（Auxiliary Vector） int main(int argc, char argv[]) ，argc 表示参数的个数，*argv数组 是参数 动态链接器的 步骤 和 实现 步骤： 启动动态链接器本身 动态链接器本身也是一个共享对象，因此它的编写除了不能依赖于其他任何共享对象，而且本身所需要的全局和静态变量的重定位工作也由它本身来完成，因此有一段精致的启动代码称之为 自举（Bootstrap） 装载所有需要的共享对象 动态链接器会根据 .dynamic 段中所依赖的共享对象，使用 广度优先的图遍历 算法，来按顺序状态共享对象；全局符号表（Global Symbol Table） 的介入，为了解决相同符号名的链接冲突，如已存在，则后加入的符号被忽略 重定位和初始化 动态链接器根据进程的全局符号表，对需要重定位的位置进行修正，如果某个共享对象有 .init 段，那么动态链接器会执行，实现共享对象 特有的 初始化过程（常见的，C++全局/静态对象的构造就在此初始化） 实现： 普及：内核在装载完 ELF 可执行文件以后，就返回到用户空间，将控制权交给程序的入口。对于静态链接，入口地址是 e_entry 制定的地址，对于动态链接，入口地址是将动态链接器映射至进程地址空间，然后把控制权交给动态链接器 普及：Linux 动态链接器：/lib/ld-linux.so.2 -&gt; /lib/ld-x.y.z.so 动态链接器在实现中的 几个问题 动态链接器本身是动态链接还是静态链接？ 答：静态链接，不依赖于任何共享对象 动态链接器本身必须是 PIC 吗？答：不一定，如果是 PIC 会简单些 动态链接器可以被当作可执行文件运行，装载地址是多少？答：0x00000000 无效的，内核 会装载它时 分配 一个 有效 的 灵活技术：显示运行时链接（Explicit Run-time Linking） 顾名思义：让程序自己在运行时控制加载制定的模块，并且可以在不需要该模块时将其卸载，操作对象是 DLL 动态链接库提供了 4 个 API 来实现，它们分别是：dlopen()，dlsym()，dlerror()，dlclose() 总结一波： 动态链接可以更加有效地利用内存和磁盘资源，可以更加方便的维护升级程序，可以让程序的重用变得更加有效和可行 装载时重定位和地址无关代码是解决绝对地址引用的两个方法，装载时重定位的缺点是无法共享代码段，但是它的运行速度较快；而地址无关代码的缺点是运行速度较慢，但它可以实现代码段在各个进程之间的共享，还介绍了 ELF 的延迟绑定 PLT 技术 .interp、.dynamic、动态符号表、重定位表等接口，它们是实现 ELF 动态链接的关键结构。动态链接器实现自举，装载共享对象，实现重定位和初始化的过程，实现动态链接，最后关键技术：显示运行时链接","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（六）","slug":"读书笔记-程序员的自我修养（六）","date":"2017-05-24T02:24:44.000Z","updated":"2017-05-24T02:27:54.000Z","comments":true,"path":"2017/05/24/读书笔记-程序员的自我修养（六）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/24/读书笔记-程序员的自我修养（六）/","excerpt":"","text":"可执行文件的装载与进程前言：源文件经过编译，链接过程，生成了目标可执行文件，可执行文件只有装载到内存以后才能被CPU执行 程序 和 进程：前者理解为一些预先编译好的指令和数据集合的一个 文件，是一个 静态 的概念，后者理解为程序运行时的一个 过程，是一个 动态 的概念 每个进程都被操作系统分配以 虚拟的地址空间（Virtual Address Space） 来供运行时分配使用，如果被操作系统捕捉到进程非法访问了额外控件，将当做 非法操作强制结束进程，常见的 Windows：”进程因非法操作需要关闭” 和 Linux：Segmentation fault 限制： 对于32位系统而言，允许分配给进程最大为：4GB的地址空间使用，而64位系统，则17179869184GB，即使 4GB，操作系统也会分配占用之后，最终留给进程最大3GB的地址空间使用，再通俗一点：整个进程在执行的时候，所有代码、数据包括通过 C 语言 malloc() 等方法申请的虚拟空间之和不得超过 3GB PAE（Physical Address Extension）和 AWE（Address Windowing Extension）：Intel 扩展了地址线，由 对应的32根（32位）扩展到了 36根 地址线，为此 多出来了256MB的物理空间，使用 窗口映射 技术，变向的增大了内存空间，进而也打破了 3GB 的限制，作为一种补救地址空间不够大的非常规手段 装载的方式 原理：程序执行时所需要的指令和数据必须 在内存中 才能够正常运行 装载的方法：都是利用了 程序局部性 的原理，即某一时刻程序只用到了局部的一些执行和数据，并非全局 以时间换取空间（淘汰）：覆盖装入（Overlay） 页映射（Paging），通常32位的Intel都是用4096字节的页作为页长，假设内存为16K，那么会被分为4个页，假设程序需要32K的内存，即需要8个页的空间，那么如何在4个页中不影响程序执行的情况下，自如装载8个页呢？ 内存页的分配算法 先进先出算法（FIFO） 最少使用算法（LUR） 从 操作系统角度 看可执行文件的装载，干了三件事 创建 一个独立的虚拟地址空间（这也是进程最关键的特征，实质上是创建映射函数所需要的相应的数据结构） 读取 可执行文件头，并建立虚拟空间与可执行文件的映射关系 将CPU的指令寄存器设置成可执行文件的入口地址，启动运行 操作系统通过不断的 页错误 来不停地将程序通过虚拟地址管理器装载到物理内存，进程才得以正常运行 进程虚拟空间 分布 区分概念 段 和 页 的关系：ELF段在映射时长度应该都是系统页长度的 整数倍，如果不是，那么多余部分也会占用一个页，进而造成 浪费，实际上，操作系统装载可执行文件时，只会根据段的 权限 来区分，对于相同权限的段，把它们合并到一起当做一个段来映射 普及概念 Linux 中将进程虚拟空间中的一个段叫做 虚拟内存区域（VMA，Virtual Memory Area），Windows 叫做 虚拟段（Virtual Section） 两次合并：第一次是链接器把各个目标文件中的相同段（Section，链接视图）合并，统一存放于可执行文件中，第二次是操作系统按照权限把可执行文件中的各个段（Segement，执行视图）合并，映射到虚拟内存区域中 核心：操作系统 通过给进程空间划分出一个个 VMA 来 管理 进程的虚拟空间，基本原则是将相同 权限 属性的、有相同 映像文件 的映射成一个VMA，一个进程基本上可以分为如下几 种 VMA区域： 代码VMA，权限只读、可执行；有映像文件 数据VMA，权限可读写，可执行；有映像文件 堆VMA，权限可读写、可执行；无映像文件，匿名，可向上扩展 栈VMA，权限可读写、不可执行；无映像文件，匿名，可向下扩展 一些限制 堆的 最大 申请数量：受操作系统版本、程序本身大小、用到的动态/共享库数量、大小、程序栈数量、大小等因素影响（随机地址空间分布技术） 段地址 对齐：受页和段的长度 整数倍映射 问题，Unix采取了 段合并 映射的方法：各个段接壤部分共享一个物理页面 进程栈 初始化：进程初始化启动之前，一些系统环境变量和进程的运行 参数 会提前保存到 Stack VMA 中，程序的库部分会把堆栈里面的初始化信息中的参数信息传递给 main() 的 argc 和 argv 两个参数 大致了解：Linux 内核装载 ELF 过程简介 bash 进程会调用 fork() 系统调用创建一个新的进程，然后新的进程调用 execve() 系统调用加载执行指定的 ELF 文件 检查 ELF 可执行文件格式的有效性，比如魔数、程序头表中段的数量 寻找动态链接的 .interp 段，设置动态链接器路径 根据 ELF 可执行文件的程序头表的描述，对 ELF 文件进行映射，比如代码、数据、只读数据 初始化 ELF 进程环境，动态链接准备 将系统调用的返回地址修改成 ELF 可执行文件的入口点 大致了解：Windows PE 的装载 过程简介 先读取文件的第一个页，包含了 DOS 头、PE文件头 和 段表 检查进程地址空间中，目标地址是否可用 使用段表中提供的信息，将 PE 文件中所有的段一一映射到地址空间中相应的位置 如果装载地址不是目标地址，则进行 Rebasing 装载所有 PE 文件所需要的 DLL 文件 对 PE 文件中的所有导入符号进行解析 根据 PE 头中制定的参数，建立初始化栈和堆 建立主线程并启动进程","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（五）","slug":"读书笔记-程序员的自我修养（五）","date":"2017-05-18T02:37:18.000Z","updated":"2017-05-18T02:39:00.000Z","comments":true,"path":"2017/05/18/读书笔记-程序员的自我修养（五）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/18/读书笔记-程序员的自我修养（五）/","excerpt":"","text":"静态链接 到底做了什么？ 模块间符号的引用，其实就是链接器的主要职责，即把各个模块之间相互引用的部分都处理好，使得各个模块之间能够正确地衔接，通俗一点来讲：两个目标文件如何链接成一个可执行文件。实质 上是将各个 目标文件 中的 地址，结合其他目标文件，包括了 运行时库（Runtime Library），确定其正确的地址，以下： 任务一： 空间与地址分配（Address and Storage）：合并-重组各个目标文件的段，以完成空间和地址的分配 共识：可执行文件中的代码段和数据段都是由输入的目标文件中合并而来的 【摒弃】 方案一：按序叠加：直接将各个目标文件中的相应段依次叠加到一起，缺点就是：内存空间大量碎片化。 方案二：相似段合并：1. 空间与地址分配：先扫描所有输入的目标文件，获取各个段的长度，属性，位置，将输入目标文件中的符号表中所有的符号定义和引用统一放到一个 全局符号表 中。2. 符号解析与重定位：根据第一部收集的所有信息，进行符号解析、重定位、调整代码中的地址（增加偏移量） 等 任务二： 符号解析与重定位（Resolution and Relocation） 重定位 ：输入目标文件中，凡是引用了 外部符号，全用 0x0000000 这 4 个字节来代替，凡是引用了 外部函数，全用 0xFFFFFFFC 这四个字节来代替。链接器负责把目标文件被外部引用的函数符号的 偏移量，来 替换 这些初始代替量，链接写入输出 可执行文件 中 重定位表 ：链接器用于识别哪些引用的符号或者函数需要重定位，使用 objdump -r a.o 来查看 符号解析 ：之所以链接是因为目标文件中用到的符号被定义在其他目标文件中，使用 objdump -s a.o 来查看符号表，其中 UND 的符号就是未定义类型，就是 待链接对象，即链接的过程经历了符号解析 指令修正方式：由于不同处理器的指令千差万别，寻址的方式也不尽相同，因此在链接过程中替换目标文件地址，需要经历指令修正来确保地址有效性，其中 绝对寻址修正 后的地址为该符号的实际地址，相对寻址修成 后的地址为符号距离被修正位置的地址差 番外介绍：特殊模块：COMMON块 作用：用于链接时存放待链接的 多个命名相同的弱符号，作为储备池，因为链接器无法区分符号类型，故无法判断是否一致，因此链接器链接的选择原则是： 取占用空间最大的那个弱符号为准 任务三： 静态库链接（.a/.lib） 静态库可以简单的看成 一组目标文件的集合，用 ar lib 等工具可以看静态库的内容 静态库里面的一个目标文件只包含一个函数，避免链接函数过多导致程序臃肿，空间浪费 使用 gcc -static --verbose -fno-builtin hello.c 查看详细的链接过程，涉及到的目标文件非常多，过程也相当复杂 综上：链接的 过程控制 链接过程要确定的内容有：使用哪些目标文件？使用哪些库文件？是否在最终可执行文件中保留调试信息？输出文件格式是什么？是否导出符号表等 链接器支持 使用命令行参数控制、将链接指令存放在目标文件里、使用链接控制脚本 来完成以上内容 ld 链接器的链接脚本语法继承于 AT&amp;T 链接器命令语言的语法，风格有点像 C 语言，分为 命令语句 和 赋值语句 BFD库 的出现，旨在解决不同软硬件平台上，通过一种 统一 的接口来处理不同的目标文件格式","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（四）","slug":"读书笔记-程序员的自我修养（四）","date":"2017-05-13T02:50:07.000Z","updated":"2017-05-13T02:52:40.000Z","comments":true,"path":"2017/05/13/读书笔记-程序员的自我修养（四）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/13/读书笔记-程序员的自我修养（四）/","excerpt":"","text":"链接的接口：符号 普及 : 链接的过程 实际上 就是 相互拼合 的过程，即目标文件中的（函数和变量） 地址引用。符号 是拼合剂 普及 : 我们将函数和变量统称为 符号（Symbol），函数名货变量名就是 符号名（Symbol Name） 普及：符号统一存放在目标文件的 符号表（Symbol Table） 中，每个定义的符号有一个对应的 符号值（Symbol Value） 主要关注的 链接对象 有：1. 定义在本目标文件的 全局符号，可以被其他目标文件引用 2. 在本目标文件中引用的 全局符号，却没有定义在本目标文件中，这一般叫做外部符号 ELF符号表 [.symtab] 结构详解： 逻辑结构：Elf32_Sym 结构体 对应一个符号，符号表是一个 数组，其中 符号类型和绑定信息（st_info）：类型：局部，全局，弱引用，绑定信息：位置，对象，函数，段，文件 符号所在段（st_shndx）：符号定义在本目标文件中，即对应段的下表，如不在，则跟 深入静态链接 的 COMMON块 有关 符号值（st_value）：依据符号所在段不同，值也会有不同的类型 特殊符号：有些符号并没有在你的程序中定义，但是你可以直接声明并且引用它，称之为特殊符号，比如：__executable_start，__etext，__edata，__end 这些符号当且仅在 链接过程中控制 符号的管理 修饰与函数签名：为了防止程序中的符号冲突，先后发明了 名称空间（namespace），符号修饰（Name Decoration） 等机制，以 函数签名（Function Signature） 作为符号的唯一标识，避免多个符号冲突，链接器无法识别 exten “C”：C++中用来声明或定义一个 C 符号的语法，配合 __cplusplus 来定义变量，这样就可以在 C 或 C++ 中正确的定义符号，使得链接器能够找到目标符号进行链接 弱符号和强符号： 都是针对定义而言的，编译器默认函数和初始化了的全局变量为 强符号（Strong Symbol），未初始化的全局变量为 弱符号（Weak Symbol），链接器会在链接的时候，遵循3种选择规则，来选择强符号还是弱符号：1. 相同变量强弱都定义，选择强，2. 不允许强符号被多次定义，3. 都是弱，选择占用空间最大的 弱引用和强引用：当链接器在引用决议时未发现符号就报错时，就是强引用，相反，不报错的就是弱引用。之所以有弱引用的存在，是为了使得程序可以在未发现符号的时候，使用原来库的定义，即便去掉了某个模块，也不会报错，方便解耦 调式信息 DWARF（Debug With Arbitrary Record Format） 使用命令 strip 来去掉 ELF 文件中的调试信息， 大幅度减少文件大小","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（三）","slug":"读书笔记-程序员的自我修养（三）","date":"2017-05-09T02:16:33.000Z","updated":"2017-05-09T02:20:02.000Z","comments":true,"path":"2017/05/09/读书笔记-程序员的自我修养（三）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/09/读书笔记-程序员的自我修养（三）/","excerpt":"","text":"目标文件（ELF） 详解 目标文件 里有什么？ 目标文件的格式，从 结构 上讲，它是已经 编译后的可执行文件，只是还 没有经过链接 的过程，其中可能有些符号或有些地址还没有被 调整，本身就是按照可执行文件格式存储的 普及 : 可执行文件格式（Executable） 主要是 Windows 下的 PE（Portable Executable） 和 Linux 下的 ELF（Executable Linkable Format），都隶属于 COFF（Common file format） 的变种 普及 : 动态链接库（DLL，Dynamic Linking Library） 即（Windows 上的 .dll 和 Linux 上 .so），静态链接库（Static Linking Library） 即（Windows 上的 .lib 和 Linux 上的 .a） 普及 : ELF 格式的文件归为四类：可重定位文件（Relocatable File）、可执行文件（Executable File）、共享目标文件（Shared Object File） 、核心转储文件（Coredump File），可以用 file 命令查看 概述 ELF 剖析 目标文件是什么样的 ? 包含的内容： 机器指令代码、数据、符号表、调试信息、字符串等 按照信息的不同属性，存储的单位：节（Section） 和 段（Segment） 结构详解：使用 binutils 的工具 objdump 可以查看 .o 文件内部的结构 工具命令 查看主要段的基本信息：objdump -h SimpleSection.o 查看各个段的信息：readelf -S SimpleSection.o 查看ELF文件的长度：size SimpleSection.o 查看段的内容：objdump -s -d SimpleSection.o 查看ELF文件头：readelf -h SimpleSection.o 逻辑划分 代码段[ .text ]：机器指令代码（一般是执行语句） 数据段和只读数据段[ .data 和 .rodata ]：已初始化 的全局变量和局部静态变量 BSS段 [ .bss ]： 未初始化 的全局变量和局部静态变量，只是预留位置而已，值得注意的是：即便初始化为 0，也会放到 bss 中，因为未初始化的都是 0 其他段：列举几个：.comment 存放编译器版本信息，.debug 存放调试信息，.dynamic 存放动态链接信息，.hash 存放哈希表，.symtab 存放符号表，.plt/.got 动态连接的跳转表和全局入口表 等等 自定义段：GCC提供了一个扩展机制，是的程序员可以制定变量所处的段：attribute((section(“name”))) int global = 42 ，global变量即会存放于 name 作为段名的段中 物理划分 文件头（File Header）：描述文件 属性，其中定义了 ELF魔数（e_ident）、文件机器字节长度、数据存储方式、版本、运行平台（e_machine）、ABI版本、ELF重定位类型（e_type）、硬件平台、硬件平台版本、入口地址、程序头入口地址、段表的位置和长度（e_shoff）、段的数量 等，常定义于：/usr/include/elf.h 中，根据版本分为：Elf32_Ehdr 和 Elf64_Ehdr 段表（Section Table）：描述包含的所有段信息，比如每个段名、段的长度、在文件中的偏移、读写权限及段的其他属性。每个段的结构是由 Elf32_Shdr 的结构体组成，对于编译器和链接器来说，主要决定段的属性是类型（sh_type）（12种）和标志位（sh_flags）（读写可分配），如果段的类型是与连接相关的，那么段的链接信息就是控制如此的（sh_link、sh_info） 重定位表（sh_type = SHT_RELA）[.rel]：重定位代码段和数据段中那些对绝对地址的引用的位置 字符串表（sh_type = SHT_STRTAB）[.symtab]：ELF文件中用到的很多字符串，比如段名和变量名等，比较聪明的做法是，具体字符串存放在字符串表中，段中直接引用 偏移量 即可","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（二）","slug":"读书笔记-程序员的自我修养（二）","date":"2017-05-08T02:24:26.000Z","updated":"2017-05-08T02:25:36.000Z","comments":true,"path":"2017/05/08/读书笔记-程序员的自我修养（二）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/08/读书笔记-程序员的自我修养（二）/","excerpt":"","text":"编译和链接 编译和链接： 通常将编译和链接合并到一起的过程称为 构建（Build），可以分解成以下 4 个步骤 预编译（Propressing） 源文件 和 头文件 被预编译器预编译成一个 .i 或者 .ii（cpp）的文件 期间主要处理那些源代码文件中的以 # 开始的预编译命令，比如 #include，#define 等 经过预编译后的 .i 文件 不包含任何宏定义，并且引用的文件已经全部被插入到 .i 文件中，删除了所有注释，处理了所有条件预编译指令（#if，#ifdef，#elif，#else，#endif），保留了所有#progma编译器命令 为此，当需要判断 宏定义，包含的头文件是否正确时，可以查看预编译后的文件来确定问题（gcc -E hello.c -o hello.i） 编译（Compilation） 编译过程就是把预编译完的文件（.i / .ii）进行一些列 词法分析，语法分析，语义分析及优化 后生成相应的 汇编代码文件（.s） 如今GCC已经把预编译和编译两个步骤合二为一了，使用叫做 cc1 的程序来完成（gcc -S hello.c -o hello.s） 实际 gcc 这个命令只是这些后台程序的 包装，它会根据不同的参数要求去调用预编译编译程序 cc1，汇编器 as，链接器 Id 汇编（Assembly） 汇编过程只是根据汇编指令和机器指令的对照表一一翻译就可以了（gcc -c hello.s -o hello.o），生成 目标文件（Object File） 链接（Linking） 目标文件 到 可执行文件，需要链接许多内容（静态链接和动态链接），后文会详细介绍 ld -static crt1.o crti.o crtbeginT.o hello.o –start-group -lgcc -lgcc_eh -lc -end-group crtend.o crtn.o 编译的过程： 编译器 从源代码（Source Code）到最终目标代码（Final Target Code）过程，做了以下 6 个步骤 词法分析 通过扫描器，运用一种类似于 有限状态机（Final State Machine） 的算法，将源代码的字符序列分割成一系列的 记号（Token） 词法分析产生的记号一般分为以下几类：关键字、标识符、字面量（包含数字、字符串等）和 特殊符号（如加号、等号），并将它们放到对应的 表 中 lex 程序可以实现词法分析，支持自定义词法规则 语法分析 通过 语法分析器（Grammar Parser），采用 上下文无关语法（Context-free Grammar） 的分析手段，将由扫描器产生的记号生成 语法树（Syntax Tree） 语法树就是以 表达式（Expression） 为节点的树，如果出现了表达式不合法，编译器就会报告语法分析阶段的错误 yacc 程序可以实现语法分析，构建一颗语法树，支持自定义语法规则 语义分析 语义分析器（Semantic Analyzer） 只对表达式完成语法层面的分析，不关心是否真正有意义，通常可以分为以下两种 静态语义（Static Semantic） 通常包括声明和类型的匹配，类型的转换，最简单的例子：赋值类型转换 动态语义（Dynamic Semantic） 一般指在运行期出现的语义相关问题，比如将0作为除数 经过语义分析之后，整个语法树的表达式都被标识了 类型，如果有些类型需要做隐式转换，语义分析程序会在语法树中 插入 相应的转换节点 中间语言生成 现代的编译器都包含 源码级优化器（Source Code Optimizer），在源代码级别有一个优化过程（比如能在编译期间确定表达式值） 直接在语法树上做优化比较困难，所以将整个语法树转换成 中间代码（Intermediate Code），比较常见的有：三地址码（Three-address Code） 和 P-代码（P-Code） 跨平台原理：中间代码使得编译器可以被分为前端和后端。编译器前端负责产生机器无关的中间代码，编译器后端将中间代码转换成目标机器代码。这样对于一些可以跨平台的编译器而言，他们可以针对不同的平台使用同一个前端和针对不同机器平台的数个后端 目标代码生成与优化 源代码级优化器产出的结果：中间代码，标志着下面的过程都属于编译器后端，包括 代码生成器（Code Generator） 和 目标代码优化器（Target Code Optimizer） 代码生成器（Code Generator） 主要是将中间代码转换成目标机器代码，依赖于目标机器的环境 目标代码优化器（Target Code Optimizer） 主要针对目标代码，在合适的寻址方式，使用位移来代替乘法运算，删除多余的指令等方面，进行优化，涉及到的技术比如： 基址比例变址寻址（Base Index Scale Addressing） 问题：此时，目标机器代码（汇编）已经生成，但是目标代码中的变量地址还没有确定，这个地址可以是本程序内定义的，也可以是其他程序模块中的，那么运行时该如何寻址？在介绍链接器之前，先说明下链接器的作用对象：目标文件都包括什么","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-程序员的自我修养（一）","slug":"读书笔记-程序员的自我修养（一）","date":"2017-05-06T02:50:04.000Z","updated":"2017-05-06T02:51:28.000Z","comments":true,"path":"2017/05/06/读书笔记-程序员的自我修养（一）/","link":"","permalink":"https://aaronshi32.github.io/2017/05/06/读书笔记-程序员的自我修养（一）/","excerpt":"","text":"计算机基础知识回顾 SMP（Symmetrical Multi-Processing）对称多处理器：每个CPU在系统中所处的地位和所发挥的功能都是一样的。通常情况下的程序不可能分解成多个不相干的子问题，除非商用的计算环境（充分发挥每个CPU的能力），所以多核处理器（Mutli-core Processor）和 SMP 通常是一个概念。 层次结构，计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。开发工具与应用程序属于同一个层次，因为它们都使用运行库提供的 应用程序编程接口（Application Programming Interface）。运行库使用操作系统提供的 系统调用接口（System call Interface），通常以软件中断方式实现提供。操作系统内核层使用硬件层提供的 硬件规格（Hardware Specification） 操作系统的一个功能是提供抽象的接口，另一个主要功能是管理硬件资源（CPU，存储器（内存和磁盘）和 I/O 设备） 不要让CPU打盹：早期的CPU是 单一 服务式，简直浪费，后来出现了分时系统（Time-Sharing System），以 协作 的方式主动让闲CPU，供其他程序使用，再到现在，操作系统接管了所有硬件资源，本身运行在一个受硬件保护的级别，所有程序都以进程的方式运转，并且允许 抢占式 的CPU分配方式 设备驱动（Device Driver），操作系统 将硬件逐渐抽象成一些列的概念。比如：UNIX 中硬件设备的访问形式跟访问普通的文件形式一样，Windows 中，图像硬件被抽象成 GDI，声音和多媒体设备被抽象成 DirectX 对象等，向上提供统一的接口供程序使用，设备驱动完成向下对硬件的适配 I/O 设备：内存和磁盘的读取和写入是通过 I/O 端口寄存器来实现的，提供读取和写入的地址，来完成磁盘数据操作 即操作系统以进程概念，使得每个进程从逻辑上来看都是独占计算机资源，实质上操作系统以抢占式的 CPU 策略，I/O 抽象模型的方式来管理这些资源 操作系统是如何管理内存的 解决的问题：如何将计算机 有限 的物理内存分配给 多个 程序使用 直接分配物理内存的弊端：地址空间不隔离（程序直接访问物理内存），内存使用效率低（缺乏有效的内存管理机制，使得频繁换入换出数据，内存的使用分配以程序为单位（粒度太大）），程序运行的地址不固定（程序每次装入内存执行时，数据和指令跳转涉及到重定位问题） 解决方法： 增加中间层来 隔离，把程序给出的地址看作是一种 虚拟地址（Virtual Address），通过某些映射方法，保证任意一个程序所能够访问的物理内存区域跟另外一个程序相互不重叠，以达到地址空间隔离的效果 分段（Segmentation）：段映射，以程序所使用的的内存为单位，从虚拟地址映射到物理地址，映射结果唯一，解决了隔离和程序地址不固定的问题 分页（Paging）：页分割，把常用的数据和代码页装载到内存中，把不常用的代码和数据保存在磁盘里，当用到的时候再取出来。若用到的页不在内存中，操作系统会受到页错误（Page Fault），然后将需要的页装载到内存中。硬件级别：MMU（Memory Management Unit）用来支持虚拟地址到物理地址的转换，已集成到CPU内部 程序执行流最小单元：线程（Thread），又称为轻量级进程（Lightweight Process，LWP） 基础概念 线程私有（局部变量，函数的参数，TLS数据），线程之间共享（全局变量，堆数据，函数里的静态变量，程序代码，打开的文件，这些就是进程所有的东西） 调度（线程数&gt;处理器时（或者单处理器应对多线程时），会模拟出来一种并发的状态，即切换不同的线程行为，称之为线程调度 至少三种状态：运行，就绪，等待，以时间片的改变作为区分 调度算法：优先级调度（Priority Schedule），轮转法（Round Robin），也区分出 IO密集型线程（IO Bound Thread） 和 CPU密集型线程（CPU Bound Thread），IO 总比 CPU 能获得更高的优先级 为了防止 饿死（Starvation） 现象： 用户指定优先级/根据进入等待状态的频繁程序提升或降低优先级/长时间得不到执行而被提升优先级，也出现了 可抢占式线程（Preemption） 线程安全 竞争与原子操作：多个线程同时访问一个共享数据，为此引出 原子性（Atomic），但原子性操作只适用于简单的操作，更复杂的数据结构访问，通常用 锁 的手段 同步与锁：同步（Synchronization） 是一种机制：保证线程访问数据的原子性。锁（Lock） 是一种手段，每个线程在访问数据或资源之前，首先试图 获取（Accquire） 锁，并在访问结束之后 释放（Release） 锁 锁的演进：二元信号量（Binary Semaphore），只允许一个线程独占，其状态有两个：占用 和 非占用，可以由一个线程获取，另一个线程释放；多元信号量（N Semaphore），允许 N 个线程并发访问共享资源；互斥量（Mutex），类似于二元信号量，但谁获得谁负责释放；临界区（Critical Section）：不同于之前的信号量，互斥量（作用域为进程内的所有线程），临界区的作用范围仅限于本线程，其他线程无法获取临界区的锁，因此也就无法访问；条件变量（Condition Variable），使用条件变量可以让许多线程一起等待某个事件的发生，当事件发生时，所有线程可以一起恢复执行 读写锁（Read-Write Lock）：三种状态分别是，自由（Free），共享（Shared）和独占（Exclusive），当处于自由状态时，试图以任何一种方式获取锁都能成功，并将锁至于对应的状态。如果锁处于共享状态，其他线程以共享的方式获取锁仍会成功（读），此时这个锁分配给了多个线程。如果其他线程试图以独占的方式获取已经处于共享状态的锁，那么他将必须等在锁被所有的线程释放后，才能将锁的状态置成独占（写） 可重入（Reentrant）：即幂等性的函数，可以称为可重入函数 过度优化：使用 volatile 关键字，解决 1. 阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回，2. 阻止编译器调整操作 volatile 变量的质量顺序，但还是无法阻止CPU动态调度换序 线程内部三种模型 多线程库的实现方式：对用户来说如果有三个线程在同时执行（用户态线程（User Thread）），对内核来说很可能只有一个线程（内核线程（Kernel Thread）），下面提及的模型都是 UT：KT 一对一模型：真正意义上的并发调度，缺点是受内核线程数量限制，内核线程上下文切换调度开销较大，使得用户线程执行效率低下 多对一模型：高效的上下文切换和几乎无限制的线程数量，缺点是一个用户线程阻塞了，那么所有线程都将无法执行 多对多模型：多个用户线程映射到多个内核线程，切换方便且避免了一个阻塞全局的情况","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"SonarQube - 安装使用调试","slug":"SonarQube安装使用调试","date":"2017-03-14T02:57:08.000Z","updated":"2017-03-16T08:36:02.000Z","comments":true,"path":"2017/03/14/SonarQube安装使用调试/","link":"","permalink":"https://aaronshi32.github.io/2017/03/14/SonarQube安装使用调试/","excerpt":"","text":"最近研究了下SonarQube工程，发现其如此强大，可以用于质量保证的任何阶段，刚好由于项目需要建立一个完整的基础质量保证”设施”，所以快马加鞭，赶紧安装部署了下，这里总结一些问题和经历 安装与运行SonarQube分为两个部分：Server 和 Scanner，其中 Server：https://www.sonarqube.org/downloads/ Scanner：https://docs.sonarqube.org/display/SCAN/Analyzing+Source+Code 其余安装环境就不赘述了：MySQL 和 Java 参考这篇文章：http://blog.csdn.net/hunterno4/article/details/11687269 问题 在配置了 sonar-project.properties 之后，运行 sonar-scanner 报如下错误： 1org.sonarqube.ws.client.HttpException: Error 500 on http://localhost:9000/api/ce/submit?projectKey=xxx&amp;projectName=yyy : &#123;&quot;errors&quot;:[&#123;&quot;msg&quot;:&quot;An error has occurred. Please contact your administrator.&quot;&#125;]&#125; 解决方法如下： 查看 /logs/web.log 得知详细原因是：Packet for query is too large (6082109 &gt; 4194304). You can change this value on the server by setting the max_allowed_packet&#39; variable 修改 MySQL 的配置，用命令行登入执行：show VARIABLES like &#39;%max_allowed_packet%&#39;; SET GLOBAL max_allowed_packet=268435456; 重启 MySQL 和 Sonar-Server 服务 尝试分析一个工程，发现已经成功打通的整套流程，SonarQube的高集成特性以及丰富的插件，可以根据实际项目需要丰富的定制。接下来我会围绕它打造一个后期的基础质量保障“设施”，首先来看看如何调试自定义扩展插件 扩展插件官方给出了扩展插件的示例：https://github.com/SonarSource/sonar-custom-plugin-example，下载下来导入工程，可以清晰的看到 org.sonarsource.plugins.example， 插件入口目录，相当于 Main 函数的作用 org.sonarsource.plugins.example.hooks ，工具钩子，可以在各个阶段自定义一些需要的操作，继承自：PostJob/PostProjectAnalysisTask org.sonarsource.plugins.example.languages ，自定义语言支持，继承自：AbstractLanguage org.sonarsource.plugins.example.measures， 自定义质量阀的衡量标准，继承自：Metrics org.sonarsource.plugins.example.rules，自定义代码规则，继承自：Sensor org.sonarsource.plugins.example.settings，自定义设置，继承自：Sensor org.sonarsource.plugins.example.web，自定义网页显示部分，继承自：web.xxx 以上这些自定义的各个模块，分别作用于 SonarQube 的基本流程里，即： 12345678910111213public void execute(Project project) &#123; ... sensorsExecutor.execute(sensorContext); decoratorsExecutor.execute(); persistenceManager.dump(); persistenceManager.setDelayedMode(false); if (project.isRoot()) &#123; if (updateStatusJob != null) &#123; updateStatusJob.execute(); &#125; postJobsExecutor.execute(sensorContext); &#125; ... 首先，初始化整个分析过程，包括加载所有的分析任务，其次，分析这些任务（Sensor和Decorator），并且把结果存储到数据库，最后，执行postjob，做相关的一些分析，因此需要根据插件作用需要，可以自行在各个阶段模块中进行扩展 调试官方提供了调试方法：https://docs.sonarqube.org/display/DEV/Build+Plugin#BuildPlugin-Debug 这里总结下步骤，避免踩坑： 在 conf/sonar.properties 中设置sonar.web.javaAdditionalOpts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8001 将插件打包部署到 extensions/plugins 中 如果你安装了SonarQube服务，请先关掉，然后用 bin/StartSonar启动，可以检查是否出现：Listening for transport dt_socket at address: 8001 在IDE中新建远程调试，打上断点，启动调试，打开localhost:8001，此时IDE会进到debug模式 好了，学会了调试，接下来就可以进一步打造我们的插件了","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"疑难杂症-解决MSYS2在Window上越用越慢的方法","slug":"疑难杂症-解决MSYS2在Window上越用越慢的方法","date":"2017-02-27T09:45:50.000Z","updated":"2017-03-16T08:39:44.000Z","comments":true,"path":"2017/02/27/疑难杂症-解决MSYS2在Window上越用越慢的方法/","link":"","permalink":"https://aaronshi32.github.io/2017/02/27/疑难杂症-解决MSYS2在Window上越用越慢的方法/","excerpt":"","text":"最近折腾电脑真是费了不少脑细胞，谁让咱用着 window 还操着 linux 的心呢，事情起因是因为习惯了在 cmd 中使用 linux 的命令，但是 cygwin 新版的界面真是不该恭维的美感，所以就把 git/bin 目录加到了 PATH 中，这样一举两得，谁知 git for windows 现在用的是 MSYS2 的环境，运行个 ls，grep要等上 1 分钟才能出结果，于是乎忍无可忍，终于在今天解决了这个问题 问题描述解决 MSYS2 在使用过程中越用越慢的问题 解决方法123456789101112mkpasswd -l -c &gt; /etc/passwdmkgroup -l -c &gt; /etc/group# 如果是window系统就在 git/etc 下面执行# 修改 /etc/nsswitch.conf，其中passwd: files #dbgroup: files #db 参考 https://gist.github.com/k-takata/9b8d143f0f3fef5abdab http://bjg.io/guide/cygwin-ad/ 终于，系统恢复了丝滑版的顺畅~","categories":[],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://aaronshi32.github.io/tags/疑难杂症/"}],"keywords":[]},{"title":"机器学习","slug":"Tensorflow学习-机器学习","date":"2017-02-13T10:27:59.000Z","updated":"2017-02-20T10:48:02.000Z","comments":true,"path":"2017/02/13/Tensorflow学习-机器学习/","link":"","permalink":"https://aaronshi32.github.io/2017/02/13/Tensorflow学习-机器学习/","excerpt":"","text":"分类 机器学习 有监督学习(Supervised) 无监督学习(UnSupervised) 理解 有一组称之为”正确”的数据提供给算法，用于监督每次的训练成果 从数据集中发掘出规律，从而将数据进行某种程度划分 问题 回归预测（Regression Predict）特征分类（Feature Classification） 聚类（Cluster） 线性回归 模型表示 关键词：训练集（Training Set）| 学习算法（Learning Algorithm）| 假说（Hypothesis） 通过学习算法找到某种假说使得训练集的数据呈现该假说规律，即：H maps from TraningSet 如何检测假说的效果，使用成本函数（cost function or loss function），有时候也叫损失函数，通常来说，假说越准确，越接近真实，其值就越小。成本函数的出现通常伴随着目标，即 When cost function defined，the goal has appearanced 线性回归通常使用的成本函数和目标为： 学习算法： 梯度下降法（Gradient Descent） 梯度下降法的缺点包括：1）靠近极小值时速度减慢，2）直线搜索可能会产生一些问题，3）可能会“之字型”地下降。 如何调节机器学习的结果： 特征缩放（Feature Scaling） 解释：在运用一些机器学习算法的时候不可避免地要对数据进行特征缩放（feature scaling），比如：在随机梯度下降（stochastic gradient descent）算法中，特征缩放有时能提高算法的收敛速度","categories":[],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://aaronshi32.github.io/tags/人工智能/"}],"keywords":[]},{"title":"Tensorflow学习-神经网络","slug":"Tensorflow学习-神经网络","date":"2017-02-08T03:34:59.000Z","updated":"2017-02-15T10:33:20.000Z","comments":true,"path":"2017/02/08/Tensorflow学习-神经网络/","link":"","permalink":"https://aaronshi32.github.io/2017/02/08/Tensorflow学习-神经网络/","excerpt":"","text":"学校里人工智能的课程，都会以神经网络作为入门，因此，也以神经网络（NNs）作为回顾和新的学习开始 首先来回忆几个概念 神经元神经元是神经网络中的一个基本单元，作用是：求得输入向量与权向量的内积后，经一个非线性传递函数得到一个标量结果 这个非线性传递函数也称之为：激励函数（ReLu） 因此对于一个基本单位神经元，他的目的就是汇合其所有的输入（外界刺激），与该神经元上的所有权值相乘（神经敏感度），通过激励（激励函数）产生相应的反应（标量结果） 神经网络神经网络由多个神经元组成，通过层的概念划分，可以分为输入层，隐含层和输出层。 神经元之间的信息传递强度，是通过权向量来定义的，结合一定的训练学习算法，权向量会不断的进行调整，即学习算法（learning algorithm）会不断的调整神经元的敏感度，让神经元在训练过程中产生不同的刺激反应 同时，神经网络结合学习算法，依赖于大量的数据来训练，每一次的训练都需要有一个评估方法，称之为成本函数（cost function），用来定量评估根据特定输入值， 计算出来的输出结果，离正确值有多远，结果有多靠谱，换句话说就是神经网络的反应与预期是否一致 为此，一个神经网络的基本可变关键因素就是：网络拓扑设计（输入层，隐含层和输出层的关系），学习算法（以何种方式来调整神经元敏感度），激励函数（神经元对外界刺激做出如何的反应），成本函数（衡量评估神经网络距离预期的差距），当然，随着深入的研究，神经网络还有许多高级可变因素，比如，dropout等 成果 最常用的两个激活函数：Sigmoid系（Logistic-Sigmoid、Tanh-Sigmoid） 实战来源：维基百科-人工神经网络 斯坦福大学UFLDL-神经网络","categories":[],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://aaronshi32.github.io/tags/人工智能/"}],"keywords":[]},{"title":"Tensorflow学习-环境搭建","slug":"Tensorflow学习-环境搭建","date":"2017-02-08T03:34:59.000Z","updated":"2017-02-10T06:55:24.000Z","comments":true,"path":"2017/02/08/Tensorflow学习-环境搭建/","link":"","permalink":"https://aaronshi32.github.io/2017/02/08/Tensorflow学习-环境搭建/","excerpt":"","text":"耳闻 Tensorflow 已经很久了，一直没有时间亲自动手体验，忙里抽闲把环境都配置好了，以此来记录学习的开始 环境配置 VMware Player 12 （免费） Ubuntu 16.04 LTS Anaconda 4.3.0 Tensorflow Library Sublime Text + Plugin 翻墙 基于 Anaconda 搭建 Tensorflow 的环境非常方便，避免GFW的干扰，提供一个环境网站：https://mirrors.tuna.tsinghua.edu.cn/ 创建虚拟机的步骤就不赘述了，用过VMware的很简单，记得安装VMware Tools ，这个很关键 下载好 Anaconda 之后，有 2 和 3 两个版本，分别对应 python 2.7 和 python 3.5，chmod 之后就可以一路安装了，记得添加到PATH中，这样默认的python环境就升级了 打开终端，输入以下命令 123456789$ conda create -n tensorflow python=2.7$ source activate tensorflow(tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp27-none-linux_x86_64.whl(tensorflow)$ pip install --ignore-installed --upgrade $TF_BINARY_URL$ source deactivate 下载安装 Sublime Text，安装 Package Control 之后依次添加以下插件： Anaconda 其中 Anaconda 配置参考：http://www.cnblogs.com/nx520zj/p/5787393.html 去掉代码检测提示框：https://segmentfault.com/q/1010000002415020 这样，Tensorflow 的环境就搭建成功了，总体来说还是非常方便的，保证一个通畅的网络，翻墙很关键！ 试运行一个线性拟合 Demo 点此下载：line.py 得到如下输出：","categories":[],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://aaronshi32.github.io/tags/人工智能/"}],"keywords":[]},{"title":"2017书单","slug":"2017书单","date":"2017-01-09T01:27:38.000Z","updated":"2017-12-21T08:56:58.000Z","comments":true,"path":"2017/01/09/2017书单/","link":"","permalink":"https://aaronshi32.github.io/2017/01/09/2017书单/","excerpt":"","text":"思想类 《世界很大，幸好有你》 杨澜 《局座的悄悄话》 张召忠 《有味》 汪涵 《道德经》 老子 《你从未真正拼过》 Linkedin 小说类 《摆渡人》 克莱儿麦克福尔 《殉罪者》 雷米 技术类 《Tensorflow》 《程序员的自我修养》 潘爱民 《利用Python进行数据分析》 Wes McKinney 《Spring Boot 实战》 Craig Walls","categories":[],"tags":[{"name":"日常","slug":"日常","permalink":"https://aaronshi32.github.io/tags/日常/"},{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"Markdown解析器-Showdown","slug":"Markdown解析器-Showdown","date":"2016-12-01T07:26:35.000Z","updated":"2017-03-14T03:04:50.000Z","comments":true,"path":"2016/12/01/Markdown解析器-Showdown/","link":"","permalink":"https://aaronshi32.github.io/2016/12/01/Markdown解析器-Showdown/","excerpt":"","text":"由于工作中需要将 markdown 格式的文件转换成 html，因此抽空研究了下业界的工具Showdown，Showdown 是一个可以将标准 markdown 规范解析生成基础 html 的工具，使用起来很简单，通过命令：showdown makehtml -i &lt;input&gt; -o &lt;output&gt;即可完成转化，详细的介绍请参考官方文档 Showdown，在此就不过多赘述了。 Extensions 与 Listeners通过研究发现，当需要解析一些”自定义”的 markdown 规范时，Showdown 提供了清晰良好的代码格式，方便我们扩展，包括extensions, listener的方式，可以进行注册，监听，来看 Showdown 的入口文件，里面有这样三行代码： 12345678910//src/cli/makehtml.cmd.jsfunction run() &#123; var converter = new showdown.Converter(argv); ... input = fs.readFileSync(argv.i, enc); ... output = converter.makeHtml(input);&#125; 可以分析出，converter通过接受参数，来配置各种extensions和listener，然后直接从源文件中读取，经过 makeHtml 一转换就变成 html 了 官方也提供了几个现有的 extensions， 如 table-extension prettify-extension 等，这些现有的extensions都是对 markdown 的元素进行了自定义的解析和渲染，如果是基于标准的 markdown 语法，使用这种方式进行自定义渲染就非常方便了 关于 Listeners 可以参考下面的工作原理章节 工作原理关于工作原理，可以用一句话来概括：Showdown使用正则表达式解析 markdown 语法，然后直接渲染成 html，注意这里面有两个关键词： 正则表达式解析 来看一个 Parser 的源码片段： 123456789101112131415161718192021222324// 斜体和黑体的解析器：italicsAndBoldshowdown.subParser('italicsAndBold', function (text, options, globals) &#123; 'use strict'; text = globals.converter._dispatch('italicsAndBold.before', text, options, globals); if (options.literalMidWordUnderscores) &#123; //underscores // Since we are consuming a \\s character, we need to add it text = text.replace(/(^|\\s|&gt;|\\b)__(?=\\S)([\\s\\S]+?)__(?=\\b|&lt;|\\s|$)/gm, '$1&lt;strong&gt;$2&lt;/strong&gt;'); text = text.replace(/(^|\\s|&gt;|\\b)_(?=\\S)([\\s\\S]+?)_(?=\\b|&lt;|\\s|$)/gm, '$1&lt;em&gt;$2&lt;/em&gt;'); //asterisks text = text.replace(/(\\*\\*)(?=\\S)([^\\r]*?\\S[*]*)\\1/g, '&lt;strong&gt;$2&lt;/strong&gt;'); text = text.replace(/(\\*)(?=\\S)([^\\r]*?\\S)\\1/g, '&lt;em&gt;$2&lt;/em&gt;'); &#125; else &#123; // &lt;strong&gt; must go first: text = text.replace(/(\\*\\*|__)(?=\\S)([^\\r]*?\\S[*_]*)\\1/g, '&lt;strong&gt;$2&lt;/strong&gt;'); text = text.replace(/(\\*|_)(?=\\S)([^\\r]*?\\S)\\1/g, '&lt;em&gt;$2&lt;/em&gt;'); &#125; text = globals.converter._dispatch('italicsAndBold.after', text, options, globals); return text;&#125;); 每个 Parser 的开始和结束，都抛出了相应的事件供监听，这就是 listener 扩展的机制，每次处理的结果都是返回 text 文本，可以看到在解析器中，对输入的文本进行正则表达式的匹配并直接替换成了相应的 html 元素 直接渲染 所谓直接渲染，就是上面代码中的replace，这样的处理为后续的需求埋下隐患： 如果某个 markdown 片段需要作为整体的渲染，则无法满足 如果对渲染之后的 html 进行样式更改，加入css，则无法满足 可以看出，replace 替换的仅仅是 html 基本元素样式，且没有 id，class 等信息，因此极大程度上约束了生成的 html 样式，并不利于满足一些实际需求，然而 Showdown 的代码架构，将各个 markdown 元素分别定义了单独的解析器，这就为我们提供了一个思路，可以根据自定义的 markdown 的格式通过自定义的 parser 解析出来就好了，例如： 123456### start 修订记录 ###1.0date: 11.32.0date: 12.9### end 修订记录 ### 解析器可以以 start 和 end 作为判断，整体将修订记录渲染成想要的格式，因此，对 Showdown 工程有以下重构想法： 解析和渲染解耦，不通过 replace 直接完成, 而是通过 taffydb 将解析出来的数据进行存储(参考jsdoc)，这样做的好处是：规则制定者可以自定义 markdown 语法片段并通过解析器解析出来，然后存放到数据库中，不需要关心接下来如何渲染，前端工程师可以直接从数据库中取出相应的片段信息，配合css，进行定制化渲染。借助于中间数据库的解耦，使得最后生成出来的html可以加入css样式，从而满足一切定制化需求，即 解析 - 数据 -渲染 总结以上是在结合工作需求的基础上研究 Showdown 工具的一些想法，还是软件工程里的一句老话：从需求出发的改动才附有意义","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"前端资源打包工具-WebPack","slug":"前端资源打包工具-WebPack","date":"2016-11-30T01:08:26.000Z","updated":"2016-11-30T05:48:24.000Z","comments":true,"path":"2016/11/30/前端资源打包工具-WebPack/","link":"","permalink":"https://aaronshi32.github.io/2016/11/30/前端资源打包工具-WebPack/","excerpt":"","text":"WebPack 是一个前端资源打包工具，借助于Loader它可以将任何前端资源(js/image/css/…)统一转换为原生JS 代码，通过静态分析构建模块之间的依赖关系，将涉及到资源分类打包成不同的模块，这些模块在浏览器，Nodejs 中可以按需进行加载，可提升加载效率。同时，WebPack 的打包也非常高效，Webpack 使用异步 I/O 和多级缓存提高运行效率，这使得 Webpack 能够以令人难以置信的速度快速增量编译。 12官方文档：http://webpack.github.io/docs/中文文档：http://webpackdoc.com/index.html 以上两个文档已经非常全面的阐述了 WebPack 强大的功能，下面针对几个关键点进行实战 解释一切资源：Loaders由于 WebPack 打包的来源只能是原生 JS 代码，因此许多静态资源(图片/CSS), 非JS写的代码(Coffee 和 JSX)需要以一种转换方式转换成 JS 代码，为此 Loader 应运而生 Loader 作为一个单独的模块，其具有以下几个特征： 链式处理方式，资源可被多个 Loader 相互转化，但最终的结果是 JS 支持同步或异步的处理方式 Function 级别存在，可运行于NodeJS甚至其他的环境中 支持正则表达式等特性，可通过npm来发布 总而言之，Loader 作为一个JS代码的转义器，有任何需要被 WebPack 打包的非原生 JS 资源，都可以通过内置/自定义的 Loader 加以转换，供打包使用 使用方式：npm install xxx-loader --save-dev Loader列表参考： List of Loaders 丰富的插件：Plugins在打包过程中，WebPack 还允许借助各种插件，对打包过程、生成的结果进行处理，比如最简单的借助于 UglifyJS 实现压缩和混淆，使用如下命令： new webpack.optimize.UglifyJsPlugin([options]) 即可生成压缩混淆之后的打包文件，同理，内置的插件可以做更多的事情 使用方式：在配置文件中配置 Plugin列表参考： List of Plugin 配置文件：webpack.config.js在大型项目中，WebPack 通常借助于配置文件 webpack.config.js 将打包过程所需执行的步骤，插件统一进行管理，同时方便发布系统实时监控打包，配置文件的内容通常如下： 1234567891011121314151617181920212223//WebPack配置文件var webpack = require('webpack');module.exports = &#123; entry: './entry.js', output: &#123; path: __dirname, filename: 'bundle.js' &#125;, module: &#123; loaders: [&#123; test: /\\.css$/, loader: 'style!css' &#125;] &#125;, plugins: [ new webpack.optimize.UglifyJsPlugin(&#123; mangle: false, compress: false &#125;), new webpack.BannerPlugin('This file is created by ChenS') ]&#125; 可以看出，entry中配置要打包的文件，output打包之后的文件输出路径，module里配置各种 Loader，以 test 的正则表达式匹配资源文件格式，Loader 传入名称，在plugins里配置各种插件以及选项，比如上述 UglifyJsPlugin 禁用了混淆和压缩，有了这个配置文件，在使用 WebPack时就可以直接运行webpack命令，一切轻松搞定 以上Demo工程可点此下载：node-webpack-demo 总结WebPack 的基础实战在上面分析完了，更多完整功能用法，请参考WebPack","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://aaronshi32.github.io/tags/JavaScript/"},{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"读书笔记-大话设计模式","slug":"读书笔记-大话设计模式","date":"2016-11-17T09:53:00.000Z","updated":"2016-12-01T03:01:58.000Z","comments":true,"path":"2016/11/17/读书笔记-大话设计模式/","link":"","permalink":"https://aaronshi32.github.io/2016/11/17/读书笔记-大话设计模式/","excerpt":"","text":"迪米特法则 合成/聚合复用原则 原型模式 模板模式 外观模式 建造者模式 适配器模式 备忘录模式 组合模式 迭代器模式 桥接模式 命令模式 职责链模式 中介模式 享元模式 解释器模式 *访问者模式 迪米特法则 也叫最少知识原则，即：类的设计要降低耦合，如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用 在类的结构设计上，每一个类都应当尽量降低成员的访问权限，设计时应当考虑两个类是直接发生调用关系，还是通过第三方来搭建关系 合成/聚合复用原则 尽量使用合成/聚合，尽量不要使用类继承，因为父类的改变，会影响到所有子类 聚合表示一种弱的拥有关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分。合成是一种强的拥有关系，体现的是严格的部分和整体的关系。 大雁拥有翅膀（合成），许多大雁聚合成雁群（聚合） 原型模式 深复制：把引用对象的变量指向复制过的新对象，而不是原有的被引用的对象 浅复制：被复制对象的鄋变量都含有与原来的对象相同的值，而所有对其他对象的引用都仍然指向原来的对象 如何实现深复制： 用 私有构造函数 创建引用对象，然后再clone方法里调用私有构造函数，完成克隆，其他的值引用则在clone里面直接赋值就好了 模板模式 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，模板方法是的子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤 一切逻辑都在父类中写好，需要延迟交给子类的部分，通过让子类@Override方法来实现，或者抽象类实现逻辑，具体类实现细节 外观模式 为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用，比如，基金是各种股票的外观模式，购买者只需要和基金打交道就好了 分层的处理：Facade类，承上启下的作用，对外暴露的接口简单，统一 建造者模式 Builder 和 Director： Builder是抽象类，用于让开发者实现一些细节步骤，Director里面包含了Buider的实例，用于封装一些操作逻辑，这样开发者每次只需要根据自己的需求实现Builder，然后交给Director就可以了，不用care操作逻辑是否有遗漏 适用于当创建复杂对象的算法应该独立于该对象的组成部分以及他们的装配方式时适用的模式，即将一个复杂对象的构建与它的表示分离，使得同样的构建过程（Director）可以创建不同的表示(Builder) 状态模式 当一个对象的内在状态改变时允许改变其行为，这个对象看起来像是改变了其类 状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂时，把状态的判断逻辑转移到表示不同状态的一系列类当中（实际！） 适配器模式 将一个类的接口转换成客户希望的另外一个接口，Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 使用一个已经存在的类，但如果它的接口，也就是它的方法和你的要求不相同时，就应该考虑用适配器模式，即：使用一个Adapter类实现抽象接口，里面持有待适配的对象，在Override接口方法的时候，将待适配对象的方法实现到接口中 备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 Originator(发起人，负责创建一个备忘录，即在SaveStatus时创建个Mememto) 和 Memento(备忘录，负责创建状态副本，保存在自己的类中) 和 Caretaker（管理者，负责管理内部的状态副本get和set） 1234567891011121314151617181920212223242526272829303132333435363738class Originator &#123; public Mememto SaveState()&#123; return new Memento(vit,atk,def) &#125; public void RecoveryState(Mememto state)&#123; this.vit = state.vit; this.atk = state.atk; this.def = state.def; &#125;&#125;class Memento &#123; private int vit; private int atk; private int def; public Memento(int vit, int atk, int def)&#123; this.vit = vit; this.atk = atk; this.def = def; &#125; /... get/set .../&#125;class Caretaker &#123; private Memento memento; /... get/set .../&#125;//----------To Do----------Caretaker.memento = Originator.SaveState();Originator.RecoveryState(Caretaker.memento); 组合模式 将对象组合成属性结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性 “部分-整体” 的关系实质上为 “树叶-根”的关系，所有的组件实现统一的接口，这个接口包含扩展组件的能力，即 123456789101112abstarct class Component&#123; protected string name; public Component(string name)&#123; this.name = name; &#125; public abstarct void Add(Compoent c); // 扩展能力 public abstarct void Remove(Compoent c); // 扩展能力 public abstarct void Display(Compoent c); // 各司其职&#125; 迭代器模式 提供一种方法顺序访问一个聚合对象中各个元素，而又不暴露该对象的内部表示，即当你需要访问一个聚集对象，而且不管这些对象是什么，就应该考虑用迭代器模式 迭代器抽象类（Iterator） 和 迭代器具体类 (ConcreteIterator) 聚集抽象类（Aggregate）和 聚集具体类（ConcreteAggregate） 123456789101112131415161718192021222324252627282930abstaract class Iterator &#123; public abstract object First(); public abstract object Next(); public abstract bool IsDone(); public abstract object CurrentItem();&#125;abstaract class Aggregate &#123; public abstract Iterator createIterator();&#125; class ConcreteAggregate：Aggregate &#123; private IList&lt;object&gt; items = new List&lt;object&gt;(); public orerride Iterator createIterator&#123; return new ConcreteIterator(this); &#125;&#125; class ConcreteIterator : Iterator &#123; private ConcreteAggregate aggregate; public ConcreteIterator(ConcreteAggregate aggregate)&#123; this.aggregate = aggregate; &#125; /** * Override methods in Iterator * /&#125; 桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立的变化 Abstraction 和 Implementor 123456789101112131415161718192021222324252627282930313233abstract class Implementor &#123; public abstarct void Operation();&#125;class ConcreteImplementorA : Implenmentor&#123; public override void Operation()&#125;class ConcreteImplementorB : Implenmentor&#123; public override void Operation()&#125;class Abstraction &#123; protected Implementor implementor; public void SetImplementor(Implementor implementor)&#123; this.implementor = implementor; &#125; public virtual void Operation()&#123;&#125;&#125;class RefinedAbstraction: Abstraction&#123; public override void Operation()&#123; implementor.Operation(); &#125;&#125;static void Main(string[] args)&#123; Abstraction ab = new RefinedAbstraction(); ab.SetImpelementor(new ConcreteImplementorA()); ad.Operation(); ab.SetImpelementor(new ConcreteImplementorB()); ad.Operation();&#125; 命令模式 分离两个类的职责，统一规划到中间的消息队列管理：客户 - 服务员 - 烤肉者 将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作，它将请求一个操作的对象与知道怎么执行一个操作的对象分隔开: Command 和 Receiver 绑定，而 Command 的调度执行，由 Invoker 负责 123456789101112131415161718192021222324252627282930313233343536373839abstract class Command&#123; protected Receiver receiver; public Command(Receiver receiver)&#123; this.receiver = receiver; &#125; abstract public void Execute();&#125;class ConcreteCommand : Command&#123; public ConcreteCommand(Receiver receiver): base(receiver)&#123;&#125; public override void Execute()&#123; receiver.Action(); &#125;&#125;class Invoker&#123; private Command command; public void SetCommand(Command command)&#123; this.command = command; &#125; public void ExecuteCommand()&#123; command.Execute(); &#125;&#125;class Receiver&#123; public void Action()&#123;&#125;&#125;public static void Main()&#123; Receiver r = new Receiver(); Command c = new ConcreteCommand(r); Invoker i = new Invoker(); i.SetCommand(c); i.ExecuteCommand();&#125; 职责链模式 使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系，将这个对象连成一个链，并沿着这条链传递该请求，知道有一个对象处理它为止（Chain） 接收者和发送者都没有对方的明确信息，且链中的对象自己也并不知道链的结构。结果是职责链可简化对象的相互连接，仅需要保持一个向后引用 随时增加或修改处理一个请求的结构，增强了给对象指派职责的灵活性，最坏情况：到末端都得不到处理，需要事先考虑全面 123456789101112131415161718abstract class Handler&#123; protected Handler successor; public void SetSuccessor(Handler successor)&#123; this.successor = successor; &#125; public abstract void HandleRequest(int request);&#125;class ConcreteHandler1 : Handler &#123; public override void HandleRequest(int request)&#123; if(request &gt;= 0 &amp;&amp; request &lt; 10)&#123; // do handle request &#125;else if(successor != null)&#123; successor.HandleRequest(request); &#125; &#125;&#125; 中介模式 对象之间大量的连接使得一个对象不可能在没有其他对象的支持下工作，系统表现为一个不可分割的整理，所谓低耦合的解决方案：中介模式其中之一 用一个中介对象来封装一系列的对象交互。中介者使得各对象不需要显示地相互引用，从而使其耦合松散，并且可以独立的改变他们之间的交互。 缺点：把交互的复杂性变成了中介者的复杂性，需要着重考虑，对象之间多对多的交互，首先应当考虑系统设计上的合理性 享元模式 如果一个应用程序使用了大量的对象，而大量的这些对象造成了很大的存储开销时就应该考虑使用享元模式，还有就是对象的大多数的外部状态，如果删除不影响的话，那么可以用相对较少的共享对象取代很多组对象，此时也应该考虑使用享元模式，比如：线程池 享元模式共享的是对象，对象数量是有限制的，因此会在工厂内部保存对象的引用，而工厂模式是生成对象，对象数量是无限制的 1234567891011121314151617181920212223abstract class Flyweight&#123; public abstract void Operation(int ee)&#125;class ConcreteFlyweight : Flyweight&#123; public override void Operation(int ee)&#123;&#125;&#125;class FlyweightFactory&#123; private Hashtable flyweights = new Hashtable(); public FlyweightFactory()&#123; //内部保留有限的对象数 flyweights.Add(\"X\", new ConcreteFlyweight()); flyweights.Add(\"Y\", new ConcreteFlyweight()); flyweights.Add(\"Z\", new ConcreteFlyweight()); &#125; public Flyweight GetFlyweight(string key)&#123; return ((Flyweight)flyweights[key]); &#125;&#125; 解释器模式 同样的一个抽象操作，需要不同的实施方法，则考虑解释器模式 缺点在于需要维护多个解释器实现 1234567891011121314151617181920212223242526abstract class AbstractExpression &#123; public abstract void Interpret(Context ctx)&#125;TerminalExpression: AbstractExpression &#123; public override void Interpret(Context ctx)&#123;&#125;&#125;NonterminalExpression: AbstractExpression &#123; public override void Interpret(Context ctx)&#123;&#125;&#125;// 全局信息class Context &#123; private string input; private string output;&#125;static void Main(string[] args)&#123; Context ctx = new Context(); AbstractExpression terminal = new TerminalExpression(); terminal.interpret(ctx); AbstractExpression terminal = new NonterminalExpression(); nonterminal.interpret(ctx);&#125; 访问者模式 表示一个作用于某对象结构中的各元素的操作，它使你可以在不改变各元素的类前提下定义作用于这些元素的新操作。 访问者模式的目的是要把处理从数据结构分离出来，有稳定的数据结构，又有易于变化的算法，使用访问者模式就是比较合理的，因为增加算法的操作变得尤为容易 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647abstract class Visitor &#123; public abstract void useAlgorithmA(concreteElementA A); public abstract void useAlgorithmB(concreteElementB B)&#125;ConcreteVisitor1: Visitor &#123; // implements&#125;ConcreteVisitor2: Visitor &#123; // implements&#125;abstract class Element&#123; public abstract void Accept(Visitor visitor);&#125; ConcreteElementr1 : Element &#123; public override void Accept(Visitor visitor)&#123; visitor.useAlgorithmA(this); &#125;&#125;ConcreteElementr2 : Element &#123; public override void Accept(Visitor visitor)&#123; visitor.useAlgorithmB(this); &#125;&#125;class Contorller &#123; //整合 visitor 和 element, 使得对外操作统一 private IList&lt;Element&gt; elements = new List&lt;Element&gt;(); public void Attach(Element element)&#123; elements.Add(element); &#125; public void Detach(Element element)&#123; elements.Remove(element); &#125; public void Accept(Visitor visitor)&#123; foreach(Element e in elements)&#123; e.Accept(visitor); &#125; &#125;&#125;","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"读书笔记-Effective JavaScript","slug":"读书笔记-Effective JavaScript","date":"2016-11-17T09:53:00.000Z","updated":"2016-12-01T02:35:48.000Z","comments":true,"path":"2016/11/17/读书笔记-Effective JavaScript/","link":"","permalink":"https://aaronshi32.github.io/2016/11/17/读书笔记-Effective JavaScript/","excerpt":"","text":"让自己习惯JavaScript 变量作用域 使用函数 对象和原型 数组和字典 库和API设计 并发 让自己习惯 JavaScript 了解你使用的JavaScript版本 Web浏览器，并不支持让程序员指定JS的版本来执行代码 严格模式（”use strict”），允许你选择在受限制的JS版本中禁用一些问题较多或者出错的特性 不要试图将严格模式和非严格模式的文件连接在一起，建议在严格模式下编写代码（ES5 中增加的，兼容ES3） 将其自身包裹在立即调用的函数（IIFE）表达式中的方式连接多个文件，是比较安全的 理解JavaScript的浮点数 大多数编程语言都有几种数值型数据类型，但JS只有一种，就是 number，也就是常理解的 double(双精度浮点数) JS中所有 位运算符 的工作方式是：将操作数转换为整数，然后使用整数位模式进行运算，最后将结果转换为标准的JS浮点数（3步），即将数字视为32位的有符号整数 浮点数的操作是出了名的不准确 0.1 + 0.2 // 0.300000000000004 0.1 + 0.2 + 0.3 ≠ 0.1 +（0.2 + 0.3） 当心浮点运算中的精度陷阱，一般都是转化为最小单位（尽可能转换成整数）去计算，因为整数在表示时不需要舍入 当心隐式的强制转换 类型错误可能被隐式的强制转换所隐藏 重载运算符 + 是进行加法运算还是字符串连接操作取决于其参数类型 对象通过valueOf方法强制转换为数字，通过toString方法强制转换为字符串 具有valueOf方法的对象应该实现toString方法，返回一个valueOf方法产生的数字字符串表示 JS中有且只有7种假值：false、0、-0、””、NaN、null 和 undefined 测试一个值是否为未定义的值，应该使用 typeOf或者与undefined进行比较而不是真值运算 原始类型优于封装对象 5个原始类型：布尔值、数字、字符串、null 和 undefined 隐式封装：当对原始值提取属性和进行方法调用时，他表现得就像已经使用了对应的对象类型封装了该值一样。例如：String的原型对象有一个toUpperCase的方法，你可以对这个原始字符串值调用这个方法 当做相等比较时，原始类型的封装对象 ≠ 原始类型值 获取和设置原始类型值的属性会隐式地创建封装对象，字符串对象的引用在用完之后立即被销毁，所以不能给字符串添加属性 &quot;hello&quot;.property = 1; &quot;hello&quot;.property; // undefined 避免对混合类型使用 == 运算符 当参数类型不同时，==运算符应用了一套难以理解的隐式强制转换规则 当使用 === 运算符时，不需要涉及任何的隐式强制转换就明白你的比较运算符 当比较不同类型的值时，使用你自己的显示强制转换使程序的行为更清晰 null == undefined // true string/number/boolean == Date // Date.toString() --&gt; Date.valueOf() string/number/boolean == 非 Date // 非 Date.valueOf() --&gt; 非 Date.toString() 了解分号插入的局限：分号插入原则 仅在 } 标记之前、一个或多个换行之后和程序输入的结尾 仅在紧接着的标记不能被解析的时候推导分号 在以（、[、+、- 或 / 字符开头的语句钱决不能省略分号 当脚本连接的时候，在脚本之间显式插入分号 在 return、throw、break、contine、++ 或 – 的参数之前决不能换行 分号不能作为for循环的头部或空语句的分隔符 视字符串为16位的代码单元序列 JS字符串有16位的代码单元组成，而不是由Unicode代码点组成 变量作用域 尽量少用全局对象 多使用局部变量 避免对全局对象添加属性 使用全局对象来做平台特性检测 始终声明局部变量 使用 var(函数作用域) 和 let(for循环局部作用域) 来声明新的局部变量 考虑使用lint工具帮助检查未绑定的变量 不要使用with 熟练掌握闭包 JavaScript允许你引用在当前函数以外定义的变量（内部函数可以访问外部成员变量，引了，该函数就成为闭包） 闭包比创建它们的函数有更长的生命周期 闭包在内部存储其外部变量的而引用，并能读写这些变量 function sandwichMaker(){ var magicIngredient = &quot;peanut butter&quot;; function make(filling){ return magicIngredient + &quot; and &quot; + filling } return make; } var f = sandwichMaker(); f(&apos;jelly&apos;) // peanut butter and jelly f(&apos;bananas&apos;) // peanut butter and bananas //那些在其所涵盖的作用域内跟踪变量的函数，称为闭包，make函数就是一个闭包 理解变量生命提升 JavaScript隐式地提升（hoists）声明部分到封闭函数的顶部，而将赋值留在原地，换句话说，变量的作用域是整个函数，但仅在var语句出现的位置进行赋值 重声明变量被视为单个变量 请手动提升局部变量的声明，从而避免混淆 使用立即调用的函数表达式（IIFE）创建局部作用域 闭包存储的是其外部变量的引用，而不是值 function wrapElements(a){ var result = [], i, n; for(i = 0, n = a.length ; i &lt; n ; i++){ result[i] = function(){ return a[i]; }; } return result; } 由于function中引用了变量i，所以该函数为每个result[i]都创建了一个闭包，且保存着对i的引用 所以i = a.length;即result[1...a.length-1]都等于a[a.length],即 undefined 立即调用的函数表达式 function wrapElements(a){ var result = []; for(var i = 0, n = a.length ; i &lt; n ; i++){ (function(j){ result[i] = function(){ return a[i]; }; })(i); } return result; } 当心命名函数表达式笨拙的作用域 var f = function(){} 当心局部块函数声明笨拙的作用域 始终将函数声明至于程序或被包含的函数的最外层，以避免不可移植的行为 局部块函数声明: 使用var声明和有条件的赋值语句代替有条件的函数声明 避免使用eval创建局部变量 不要赋予外部调用者能改变函数内部作用域的能力，即 函数内部过分依赖于 动态绑定（eval(“var x = 1”)） 如果 eval 函数代码可能创建全局变量，将此调用封装到嵌套的函数中以防止作用域污染 var y = &quot;global&quot;; function test(src){ (function(){ eval(src); })(); return y; } test(&quot;var y = &apos;local&apos;;&quot;) // global test(&quot;var z = &apos;local&apos;;&quot;) // global 间接调用eval函数优于直接调用(Node里面没有臭名昭著的eval) 尽可能间接调用eval函数，而不要直接调用eval函数：（0，eval）(src) 使用函数 理解函数调用、方法调用及构造函数调用之间的不同 在方法调用中是由调用表达式自身来确定this变量的绑定。绑定到this变量的对象被称为调用接收者(receiver) 方法调用将被查找方法属性的对象作为调用接收者 函数调用将全局对象作为其接受者，一般很少使用函数调用语法来调用方法 构造函数需要通过new运算符调用，并产生一个新的对象作为其接收者 熟练掌握高阶函数 高阶函数就是那些将函数作为 参数 或者 返回值 的函数 当发现自己在重复地写一些相同的模式时，学会借助于一个高阶函数（提炼逻辑，让callback作为参数传递）可以使代码更简洁、更高效、更可读，学会发现可以被高阶函数所取代的常见的编码模式 掌握现有库中的高阶函数，比如数组的map 使用call方法自定义接受者来调用方法 f.call（obj,arg1,arg2,arg3）与 f（arg1,arg2,arg3）不同的是第一个参数提供了一个显式的接收者对象 使用 call 方法自定义接收者来调用函数 使用 call 方法可以调用在给定的对象中不存在的方法 使用 call 方法定义高阶函数允许使用者给回调函数指定接收者 使用apply方法通过不同数量的参数调用函数 使用 apply 方法制定一个可计算的参数数组来调用可变参数的函数，apply方法需要一个参数数组，然后将数组的每一个元素作为调用的单独参数调用该函数 使用 apply 方法的第一个参数给可变参数的方法提供一个接收者 使用arguments创建可变参数的函数 JavaScript给每个函数都隐式得提供了一个名为arguments的局部变量。arguments对象给实参提供了一个类似的数组接口，它为每个实参提供了一个索引属性，还包含一个length属性用来指示参数的个数，从而可以通过遍历arguments对象的每个元素来实现可变元数的函数 如果提供了一个便利的可变参数的函数，也最好提供一个需要显示指定数组的固定元数版本 function average(){ return averageOfArray(arguments); } 永远不要修改 arguments 对象 使用 [].slice.call(arguments) 将 arguments 对象复制到一个真正的数组中再进行修改 使用变量保存 arguments 的引用 先用变量绑定到 arguments，明确作用域之后，再在嵌套函数中引用它 使用 bind 方法提取具有确定接受者的方法 提取一个方法不会将方法的接收者绑定到该方法的对象上 当给高阶函数传递对象方法时，使用匿名函数在适当的接收者上调用该方法 使用 bind 方法创建绑定到适当接收者的函数 使用 bind 方法实现函数柯里化(不懂) 将函数与其参数的一个子集绑定的技术成为函数柯里化 function.bind(null, arg1, arg2) 使用闭包而不是字符串来封装代码 当将字符串传递给eval函数以执行时，不要在字符串中包含局部变量的引用，容易在函数中引起冲突 优先接收函数，而不是eval执行的字符串，即 function repeat(n, action){ for(var i = 0 ; i &lt; n ; i++){ action(); } } 不要信赖函数的toString方法 在不同的引擎下调用toString方法的结果可能不同，所以绝不要信赖函数源代码的详细细节 toString方法的执行结果并不会暴露存储在闭包中的局部变量值 通常情况下，应该避免使用函数对象的toString方法 避免使用非标准的栈检查属性 调用栈实质当前正在执行的活动函数链 不要使用非标准的 arguments.caller 和 arguments.callee 属性 对象和原型 理解 prototype、getPrototypeOf 和 proto 之间的不同(有一个重点图) C.prototype 属性是 new C() 创建的对象的原型 Object.getPrototypeOf(obj)是ES5中检索对象原型的标准函数 Object.getPrototypeOf(u) === User.prototype obj.proto 是检索对象原型的非标准方法（不支持ES5的情况下采用） 类：是由一个构造函数 和 一个关联的原型 组成的一种设计模式 function User(name, passwordHash){ this.name = name; this.passwordHash = passwordHash; } User.prototype.toString = function(){ return &quot;sdsds&quot;; } var instance = new User(&quot;abc&quot;,&quot;abc&quot;); Function.prototype(.call/.bind/.apply) --&gt; User(.prototype) --&gt; User.prototype(.toString) --&gt; instance(.name/.passwordHash) 使用 Object.getPrototypeOf 函数而不要使用 proto 属性 获取对象原型的标准API是 Object.getPrototypeOf（） 在支持proto属性的非ES5环境中实现 getPrototypeOf if(type Object.getPrototypeOf === &quot;undefined&quot;){ Object.getPrototypeOf = function(obj){ var t = typeof obj; if(!t || ( t !== &quot;onject&quot; &amp;&amp; t !== &quot;function&quot;)){ throw new TypeError（&quot;not an object&quot;）； } return obj._proto_; } } 始终不要修改 proto 属性 使用Object.create函数给新对象设置自定义的原型 使构造函数与 new 操作符无关 防范误用构造函数可能不值得费心去做，但在跨大型代码库中共享构造函数或者构造函数来自一个共享库的时候，就需要多加防范了 当一个函数期望使用new操作符调用时，清晰地文档化该函数 通过使用 new 操作符或Object.create 方法在构造函数定义中调用自身使得该构造函数与调用语法无关 在原型中存储方法 原型是共享方法的渠道之一，将方法存储于原型中由于存储在示例对象中 将方法存储在示例对象中将创建该函数的多个副本，因为每个实例对象都有一份副本 使用闭包存储私有数据 闭包变量是私有的，只能通过局部的引用获取 将局部变量作为私有数据从而通过方法实现信息隐藏 只将实例状态存储在实例对象中 共享可变数据可能会出现问题，因为原型是被其所有的实例共享的 将可变的实力状态存储在实例对象中 认识到 this 变量的隐式绑定问题 this 变量的作用域总是由其最近的封闭函数所确定的 使用一个局部变量（通常命名为 self、me 和 that）使得this绑定对于内部函数是可用的 数组和字典 原型污染 定义：Object 是 js 对象的根，如果在 Object.prototype 上增加任何方法，那么随之使用 for…in 遍历对象属性的时候，此时增加的方法也会计算进去从而造成的原型污染，此外，一些特殊命名的变量名也会对对象造成污染。 原因：for…in 循环除了枚举出对象”自身”的属性外，还会枚举出继承过来的属性 预防： 使用 Object.create(null) 来创建一个没有原型的对象，因此原型污染就无法影响这样的对象行为 使用 hasOwnProperty 方法（只过来对象自身属性）以避免原型污染： var hasOwn= Object.prototype.hasOwnProperty; hasOwn.call(dic，”alice”) 别在 Object.prototype 中增加属性，若不小心增加了属性，也要用 Object.defineProperty方法把属性 enumerable置成false 循环和迭代 使用数组而不要使用字典来存储有序集合 for…in 循环会挑选一定的顺序来枚举对象的属性，如果是有序的，还是用for循环遍历 避免在 for…in 期间修改对象，如果需要修改，应该使用while或for循环 数组的循环优先使用for循环而不是for…in循环 使用迭代方法由于循环：forEach，map，every，some 处理数组内容的改变：map，筛选数组的内容：filter 循环只有一点优于迭代函数，那就是控制流操作，如 break 和 continue 创建 数组、对象，直接使用 var x = []，{} 即可，因为使用 Array 和 Object 不能保证是不是被污染了 库和API设计-【参数】 保持一致的约定 - 约定参数的顺序 - 宽度第一，然后高度： new Widget(320, 640) // width:320, height:240 - CSS顺时针约定：top，right，bottom，left -【参数】 在变量命名和函数签名中使用一致的约定 -【多元化】 不要偏离用户在其他开发平台中很可能遇到的约定 -【检查】真值测试是实现参数默认值的一种简明的方式（this.hostname = hostname || “localhost”），但不适用于允许0、NaN或空字符串为有效参数的情况，比如this.hostname就是等于undefined -【检查】应该提供参数默认值应当采用测试undefined的方式，而不是检查arguments.length，即 this.width = width === undefined ? 320 : width -【参数】使用接收关键字参数的选项对象，options object，既接收Alert({xxx:yyy})的方式，避免参数过多，API失去可扩展性 -【设计】避免不必要的状态，API有时候被归为两类：有状态的(Date对象)和无状态的（幂等性，输入对应固定输出），无状态的API比有状态的API，从易用性，学习容易性而言，更优。无状态的API简洁，易于扩展 -【设计】API绝对不应该重载与其他类型有重叠的类型，一个方法不应该既接收type 1又接收type 2，当重载一个结构类型与其他类型时，先测试其他类型 - 判断是不是数组：Array.isArray 和 toString.call(x) === &quot;[Object Array]&quot; - 将对象转换成数组：[].slice.call(arguments) -【设计】避免过度的强制转换，应该显示的转换，用代码写出来，而不是交给编译器 -【设计】支持方法链 - 使用方法连来连接无状态的操作 - 通过在无状态的方法中返回新对象来支持方法链 - 通过在有状态的方法中返回this来支持方法连 并发 异步的强大能力：JS的运行到完成机制(run-to-complete)，在系统里维护了一个按时间发生顺序的内部事件队列，一次调用一个已注册的回调函数，通过轮询这个队列来完成异步的操作，有序的调用回调函数。 Workers API提供了线程的能力，在一个完全隔离的状态下执行，没有获取全局作用域或应用程序主线程Web页面内容的能力 应该避免将可被并行执行的操作顺序化，嵌套的回调函数应该用Promise 对于异步的代码，多步的处理通常被分隔到时间队列的单独伦次中，因此不可能将它们全部包装在一个try语句块中。事实上，异步的API甚至根本不可能抛出异常，因为，当一个异步的错误发生时，没有一个明显的执行上下文来抛出异常！因此，异步API更加倾向于将错误表示为回调函数的特定参数，即err，在Nodejs平台中，err是回调函数的第一个参数 目前典型的JS环境中一个递归函数同步调用自身过多次会导致失败，原因是：存储过多的栈帧需要的空间量会消耗JS环境分配的空间 循环不能是异步的 使用递归函数在事件循环的单独轮次中执行迭代 function downloadOneAsync(urls, onsuccess, onfailure){ var n = urls.length; function tryNextURL(i){ if(i&gt;=n){ onfailure(&quot;xxxxxxx&quot;); return; } downloadAsync(url[i], onsuccess,function(){ tryNextURL(i+1); }); } tryNextURL(0); } 避免在主事件队列中执行代价高昂的算法，在支持Worker API的平台，该API可以用来在一个独立的事件队列中运行场计算程序，在Work API不可用或代价昂贵的环境中，考虑将计算程序分解到事件循环的多个轮次中 使用计数器来执行并行操作可以避免竞争，Js应用程序中的事件发生时不确定的，即顺序是不可预测的 同步地调用异步的回调函数扰乱了预期的操作序列，并可能导致意想不到的交错代码，也可能导致栈溢出或者错误的异常处理 Promise promise代表最终值，即并行操作完成时最终产生的结果 使用promise组合不同的并行操作，避免数据竞争 在要求有意的竞争条件时，使用select","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]},{"title":"JS文档生成工具-Jsdoc","slug":"JS文档生成工具-Jsdoc","date":"2016-11-17T09:53:00.000Z","updated":"2017-07-13T07:05:42.000Z","comments":true,"path":"2016/11/17/JS文档生成工具-Jsdoc/","link":"","permalink":"https://aaronshi32.github.io/2016/11/17/JS文档生成工具-Jsdoc/","excerpt":"","text":"Jsdoc是一款JS文档的生成工具，提供了丰富的标签，写起文档来十分方便，具体标签用法参考 Jsdoc，这里就不多赘述。但它的用处，远远不止于生成文档，最近通过研究，发现利用Jsdoc工具，可以干更多的事情，待下面剖析。 生成原理首先来谈谈Jsdoc的生成原理，即如何从注释代码生成最后的网页。这个过程其实很简单，通过文档解析器parser对每个js文件进行分析，提取出文档信息，之后的一步很关键，Jsdoc将提取出来的信息存放到了taffydb中，进而根据这些信息来生成网页。 为了更好的解释这个过程，来看Jsdoc的源码 1234/* templates/default/publish.js */exports.publish = function(taffyData, opts, tutorials) &#123; //generate Jsdoc html &#125; 生成html的代码逻辑，就在publish这关键函数中，从接受的参数来看，taffyData中已经存放好解析之后的文档信息，opts是配置文件的解析，tutorials是教程的信息，未做过多研究。那么taffyData中存放的信息试什么样子的呢？来看如下 12345678910111213141516171819202122***** Debug ******[ &#123; comment: '/**\\n* &lt;p&gt;Start ...... @public\\n* @since 1\\n */', meta: &#123; range: [Object], filename: 'LocationManager.js', lineno: 69, code: [Object], vars: [Object] &#125;, description: '&lt;p&gt;Start request location.&lt;/p&gt; ......more.&lt;/p&gt;\\n', permission: [ [Object] ], see: [ '[removeLocationU...r#removeLocationUpdates&#125;' ], params: [ [Object] ], returns: [ [Object] ], access: 'public', since: '1', name: 'requestLocationUpdates', longname: 'xxx.location.LocationManager#requestLocationUpdates', kind: 'function', memberof: 'xxx.location.LocationManager', scope: 'instance', ___id: 'T000002R003347', ___s: true &#125; ] 以上信息就是taffyData中存放的文档信息，可以看到，关键的Jsdoc信息，比如@since 1解析成了since:&#39;1&#39;，@public解析成了access:public，kind:&#39;function&#39;，经过这般解析，taffyData中的数据已经足够可以用来生成网页，从而可以看出，在publish函数中，围绕着taffydb的数据，通过各种数据处理，可以做一些更多的事情，这里只是抛砖引玉，比如统计代码的各种信息、检查Jsdoc是否符合规范等等 以一张图简要描述下Jsdoc的原理 至此，我们分析出了Jsdoc的关键信息：Jsdoc解析之后的信息全部存放到taffyData中，而这些信息作为接口publish的参数，提供了良好的扩展性 如果进一步了解信息转储，请查阅：app.js # app.jsdoc.parser.parse -&gt; parser.js # parser.createParser 这个方法 自定义扩展接下来来看看Jsdoc提供的三种自定义扩展方式，分别是：自定义EventHandler级别的插件，自定义标签，自定义抽象语法树访问器，下面来分别解释下这三种扩展方式的区别 自定义EventHandler级别的插件 这种扩展方式是最高级别的扩展，如果学过监听器设计模式，看如下代码就一目了然了，一个EventHandler插件包含了以下几个阶段的监听 1234567891011exports.handlers = &#123; parseBegin: function(sourcefiles)&#123;&#125;, fileBegin: function(filename)&#123;&#125;, beforeParse: function(filename,content)&#123;&#125;, JsdocCommentFound: function(filename, comment, lineno)&#123;&#125;, symbolFound: function(..params)&#123; &#125;, newDoclet: function(doclet) &#123;&#125;, fileComplete: function(filename,content)&#123;&#125;, parseComplete: function(sourcefiles, doclets)&#123;&#125;, processingComplete: function(doclets)&#123;&#125;&#125;; 不难理解，Jsdoc在生成过程中，抛出了以上这些阶段事件供扩展，每个事件的不同参数，代表的当前阶段产生的中间结果。比如在解析之前(parseBegin)，传入的参数代表源文件文件名列表，可以做一些正比表达式的匹配，指定生成某些文件的文档。在解析完一个文件的Jsdoc信息时(newDoclet)，doclet中就包括了上面taffydb中的信息。有了这几个阶段，相信很轻松的就可以扩展出任何想要的插件，关键在于插件的行为是由哪些阶段完成的。 自定义标签 这种扩展方式是中间级别的扩展，主要用于当Jsdoc官方提供的标签不能满足文档注释需要的时候，选择自定义标签来补充完善Jsdoc的能力，比如，我需要在文档中注释一个权限声明的标签，@permission，那么可以这样做 1234567891011exports.defineTags = function(dictionary) &#123; var opts = &#123; canHaveName: true, mustHaveValue: true, onTagged: function(doclet, tag) &#123; doclet.permission = doclet.permission || []; doclet.permission.push(tag); &#125; &#125; dictionary.defineTag(\"permission\", opts);&#125; Jsdoc提供了defineTags接口来自定义标签，其参数dictionary可以理解为标签字典，如上述代码描述，将自定义标签和属性，添加到dictionary中，这样就能被Jsdoc在解析中识别了，onTagged方法定义了当解析到该标签时，Jsdoc应该做出的操作，这里还是doclet，还记得吗？就是那个taffydb的数据，翻到上面那个taffydb数据信息看看，permission就在其中。自定义标签相比上面的EventHandler级别的插件，实现起来简单、方便。 自定义抽象语法树访问器 这种扩展方式时最低级别的扩展，官方文档中用了(lowest)一词。同样，来看代码 12345exports.astNodeVisitor = &#123; visitNode: function(node, e, parser, currentSourceName) &#123; // do all sorts of crazy things here &#125;&#125;; 由于直接接触的对象是抽象语法数，那么可做的事情就更多了，就好比越是接近系统底层，可扩展的能力越高，越是上层的东西，可扩展能力就越小，Jsdoc提供了astNodeVisitor接口来扩展访问到AST每个节点的行为，感兴趣的同学可以好好实战一番，这里就不过多赘述了 更多Jsdoc的主要原理和扩展方式在上面分析完了，更多完整功能用法，请参考Jsdoc","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://aaronshi32.github.io/tags/JavaScript/"},{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"Node命令行工具-Yargs和Commander","slug":"Node命令行工具-Yargs和Commander","date":"2016-11-16T10:25:40.000Z","updated":"2016-11-17T09:15:38.000Z","comments":true,"path":"2016/11/16/Node命令行工具-Yargs和Commander/","link":"","permalink":"https://aaronshi32.github.io/2016/11/16/Node命令行工具-Yargs和Commander/","excerpt":"","text":"日常使用Node时，避免不了编写几个命令行工具。作为命令行工具，最直接的就是针对输入的各种参数、选项等，执行相应的命令。使用原生的progress.argv虽然可以进行参数判断，但使用起来十分不方便，为此研究了下Node第三方命令行工具 yargs 和 commander Yargs首先来看一个简单的例子 1234567891011121314λ index -h Usage: index.js &lt;command&gt; -a [num] -b [num] Commands: add same as a + b plus same as a - b Options: -a, -A load a parameter [number] [required] -b, -B load b parameter [number] [required] -h, --help Show help [boolean] Examples: index.js add -a 10 -b 3 //compute 10 add 3 这段帮助信息是用 yargs 编写的，实现起来很简单，来看代码 123456789101112131415161718192021#!/usr/bin/env nodevar yargs = require('yargs');ARGV = yargs.usage('Usage: $0 &lt;command&gt; -a [num] -b [num]') .command('add', 'same as a + b') .command('plus', 'same as a - b') .example('$0 add -a 10 -b 3', '//compute 10 add 3') .alias('a', 'A') .alias('b', 'B') .alias('h', 'help') .number('a') .number('b') .describe('a', 'load a parameters') .describe('b', 'load b parameters') .demand(['a','b']) .help('h') .argvif(ARGV.h || ARGV.help)&#123; print(ARGV.help()); process.exit(0);&#125; 上述代码可以分为几个阶段 usage: 命令行工具的使用方法 command: 如果需要输入命令，则用 command(&#39;命令&#39;，&#39;描述&#39;) 的方式标注 example: 给出使用的例子，用 example(&#39;命令&#39;，&#39;描述&#39;) 的方式标注 alias: 对输入参数别名化，比如 -a 和 -A 是等效的 number(string,boolean,array…): 对输入的参数进行类型转换，比如.array(a), -a 10 4 3 5，那么 ARGV.a 是 [10,4,3,5] describe: 对输入参数进行描述，用 describe(&#39;参数&#39;，&#39;描述&#39;) 的方式标注 require：标注哪些参数是必备的，比如 a 和 b 的后面加入了 [require] 的描述 help/epilog: 辅助的帮助/版权信息 就这样，一个简单的命令行信息交互帮助信息就生成了，后面可以用 ARGV.xxx 获得输入的参数，做后续程序的逻辑判断。 进阶用法 ARGV._ : 获得未指定的输入参数，比如 index -a 10 -b 3 5 “no” “13”，则 ARGV._ 获得 [‘5’,’no’,’13’] .check(cb)：检查输入参数合法性，如果 cb 返回 false，则输出帮助信息并退出 .fail(cb)：当工具运行出错时，输出错误信息 更多用法请参考 yargs，一般情况下，用 yargs 快速搭建一个命令行的使用帮助信息就足够了，不建议把判断的复杂逻辑也集成到 yargs 中 Commander还是之前的例子，用 commander 实现的运行结果如下 123456789101112131415λ commander --help Usage: commander &lt;command&gt; -a [num] -b [num] Commands: add same as a + b plus same as a - b Options: -h, --help output usage information -a, -A [num] load a parameter -b, -B [num] load b parameter 来看代码 123456789101112131415161718#!/usr/bin/env nodevar program = require('commander');program .usage('&lt;command&gt; -a [num] -b [num]') .option('-a, -A [num]', 'load a parameter') .option('-b, -B [num]', 'load b parameter');program .command('add') .description('same as a + b');program .command('plus') .description('same as a - b');program.parse(process.argv); 通过对比，个人比较喜欢 commander 的代码风格，每个 command 单独处理，可以各种自定义，比如针对某个命令输出 help 信息，而 yargs 的那种分块编码，也值得借鉴，从代码量而言，yargs 和 commander 指定复杂的命令时，前者的代码量会比较少，同样，前者在功能上比后者更加丰富，适合复杂通用的命令行工具，更多用法请参考 commander 后记：Windows 上如何调用nodejs命令行工具在本机上找到任意一个npm的安装包，都能发现有 xxx.cmd 这样的文件，打开如下 1234567@IF EXIST \"%~dp0\\node.exe\" ( \"%~dp0\\node.exe\" \"%~dp0\\xxx.js\" %*) ELSE ( @SETLOCAL @SET PATHEXT=%PATHEXT:;.JS;=;% node \"%~dp0\\xxx.js\" %*) 不难理解，在window上要执行nodejs，必须要用 node xxx.js 的方式，而这段代码就是省略了前面的node，直接用 xxx 即可，比如之前的例子中，#!/usr/bin/env node用来在linux上指定脚本运行环境为node，所以可以直接用 ./script.js 加参数运行，在window上，将上面的文件中 xxx 替换成script，即可用 script 加参数运行了 如果以后涉及到用Node写两个平台通用的工具，请记住编写这个文件","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://aaronshi32.github.io/tags/JavaScript/"},{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"JS压缩混淆工具-UglifyJS","slug":"JS压缩混淆工具-UglifyJS","date":"2016-11-14T08:08:52.000Z","updated":"2016-11-16T09:39:58.000Z","comments":true,"path":"2016/11/14/JS压缩混淆工具-UglifyJS/","link":"","permalink":"https://aaronshi32.github.io/2016/11/14/JS压缩混淆工具-UglifyJS/","excerpt":"","text":"最近写了一些JS的项目，顺便研究了下UglifyJS工具，它是一款JS代码处理工具，提供了压缩，混淆和代码规范化等功能，同时还支持命令行和NodeJS两种使用方式，在代码基本”格式化”功能的基础上，可自定义扩展一些功能选项，满足具体项目中的使用。在业界内，JQuery使用UglifyJS进行代码压缩混淆，可见其结果具备准确性和稳定性。 使用方式：uglifyjs [input files] [options] SourceMapUglifyJS支持使用/生成SourceMap, 那什么是SourceMap，简单来说就是一个解码表，JS代码从原生到压缩混淆之后，从原来的几百行甚至几千行中，压缩到几十行。不仅代码行数骤减，同时经过混淆，代码的变量声明都进行了替换，因此当我们看混淆之后的代码，很难读懂代码的本意，这也是压缩混淆的初衷，减少JS代码的大小，方便网络传输，理论上对代码进行了保护。利弊相对，压缩混淆之后的代码对调试来说尤为困难，因此SourceMap就出现了。 简单来讲，压缩混淆之后的代码通过SourceMap，即可还原成原始的JS代码，这就是为什么说它是一个解码表的原因，因为反向还原了JS代码，结合到UglifyJS而言，其支持以下几个选项： source-map 指定生成一个SourceMap的文件名 source-map-root 指定SourceMap的根目录位置 source-map-url 指定SourceMap的网络路径 source-map-inline 在压缩混淆的JS代码后，追加SourceMap内容 in-source-map 指定一个SourceMap 功能：压缩使用UglifyJS进行代码压缩，-c 选项即启用压缩，例如： 12345678910111213\"use strict\";var net = require('net');const IP = \"127.0.0.1\";const PORT = 8887;var client = new net.Socket();client.connect(PORT, IP, function() &#123; console.log('CONNECTED TO: ' + IP + ':' + PORT); client.write('I am Chuck Norris!');&#125;); 压缩后变成 1\"use strict\";var net=require(\"net\");const IP=\"127.0.0.1\",PORT=8887;var client=new net.Socket;client.connect(PORT,IP,function()&#123;console.log(\"CONNECTED TO: \"+IP+\":\"+PORT),client.write(\"I am Chuck Norris!\")&#125;); 可以看出，压缩之后去掉了空行以及连续声明时候的关键字const，如果让你调试这样的出错代码，没有SourceMap，则无从下手 功能：混淆使用UglifyJS进行代码混淆，-m 选项即启用混淆，例如，还是上面的代码，经过混淆后变成 1\"use strict\";var c=require(\"net\");const e=\"127.0.0.1\";const n=8887;var o=new c.Socket;o.connect(n,e,function()&#123;console.log(\"CONNECTED TO: \"+e+\":\"+n);o.write(\"I am Chuck Norris!\")&#125;); 可以看出，混淆把变量都替换成了单字符，相比于压缩，进一步的减小了代码量 总结UglifyJS是一款出色的JS代码压缩，混淆工具，其具有丰富的功能，例如代码美化，支持NodeJS自定义编程等，更多细节请参考 UglifyJS","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://aaronshi32.github.io/tags/JavaScript/"},{"name":"工具","slug":"工具","permalink":"https://aaronshi32.github.io/tags/工具/"}],"keywords":[]},{"title":"读书笔记-Google工作整理术","slug":"读书笔记-Google工作整理术","date":"2016-10-26T09:53:00.000Z","updated":"2016-12-02T01:02:26.000Z","comments":true,"path":"2016/10/26/读书笔记-Google工作整理术/","link":"","permalink":"https://aaronshi32.github.io/2016/10/26/读书笔记-Google工作整理术/","excerpt":"","text":"认知大脑 为了实现大脑压力最小化，要把生活组织的有条不紊 让信息尽可能快地离开大脑 多重任务通常让你降低效率 利用故事去记忆 共勉句 我们做决定经常是建立在害怕失去什么的基础上，而不是考虑希望得到什么 紊乱无需让你搞到重重压力，进而举措失当，承受等大的压力，让你更加失误连连 音乐可以减缓压力 识别要比回忆轻松地多 要回忆一个事实，先努力想想第一次注意到那个事实时你正在干什么，这是很有帮助的 面对太多选择的时候，我们经常倾向于选择最熟悉的东西 做决定的关键在于你的目标是什么，并确定他们的优先次序，展望各不相同的最终结果，比较各种决定的效果。 多样性会让你和你的同事在实现目标的过程中更加出类拔萃 错误的有序 仅仅因为一直都按照某种特定方式做某事，并不意味着就该永远这样做（朝九晚五、暑假） 知识不是力量，共享知识才是力量 共勉句 分享自己的所知，鼓励别人也这么做，你就会从他们那里学有所获，他们也可以从你这里学到东西，然后你们就会胜任更好的工作 解决问题的办法不是更加辛苦的工作，而是利用现有的工具和技术，巧妙的工作 突破制约 进行组织安排时，要绕开的是实际制约而不是假性制约 对自己要坦诚，但是千万不要自我评判，坦诚的检视下你所处的环境，多听听可信赖的人的意见 要懂得什么时候忽略制约，不要第一步都迈不出去 共勉句 学会识别、接受并绕开你的实际制约，从而不在你无法改变的事情上浪费时间和精力 实际制约通常涉及你绝对无法控制的某些因素 有时候，超出我们控制范围的制约刚好就潜伏在你能控制的哪些制约的表面之下 源自情绪的制约最难识别和控制，无论面对什么制约，控制好自己的举止，行动，愿望和情绪 在不可预料的意外发生之前，对于那些面临压力时还会变本加厉的制约，要及早辨别并准备好绕开它的有效策略，这是十分重要的 目标决策 在发动汽车之前，一定要确切的搞清楚自己要到哪里去，还要知道选择什么途径去 在实现目标的方式上灵活变通 共勉句 在一件事之前，要搞清楚 你的问题是什么？，也就间接的让自己清楚目标是什么 所做的每一件事都要从自己的目标出发，切勿盲目，偏离初衷 一旦确定了某个项目的目标，先学会四处看看，确定一下可能面临的问题是否有人已经解决了，别人所用的解决办法中哪些要素可以采纳或借鉴 给别人委派任务涉及信任问题，请求别人做事情，就一定要信任别人，更不要剥夺别人学习新的东西、担负更多责任的机会 针对你的决策将会产生的不同结果，逐个试试看，形象的展望一个决定可能产生的不同结果，可以帮你明确什么才是你真正想要的 任何决定都需要经过反复推敲做出假设，写下来，每天看一遍 Google搜索的时代 不要给信息处处归档，用的时候去搜索就行了 共勉句 搜索功能是新式组织管理的基础，我们不必在文件归档方面耗时间和精力，也用不着为了找到重要信息而劳神费力 基本搜索引擎技巧 PageRank：别人说他好，才是真的好（引用的越多，越有价值） 技巧 尽量增强搜索条件的描述性（关键词多一些） 在搜索条件短语中使用引号（引号表示确认在搜索的网页中包含） 使用形容词搜索（”apple ~cheap”） 排除不想要的结果（”opera -browser”） 通过数值范围获取特定信息（…表示数值范围，”digital camera” $100…$300） 搜索特定网站（”paris hotels” site:nytimes.com） 搜索特定类型的文件（”paris hotels” filetype:xls） 信息过滤器 目标是信息存储的向导，大脑中只保存真正需要记忆的内容 大块的内容要化整为零 每周拿出些时间回顾关键信息，再次梳理归类 共勉句 幸运的是，我们接收的绝大部分信息都没有必要记住，因为大部分信息不值得我们记忆 信息的有效性取决于你的目标是什么，不断的分门别类，建立信息等级（忽略，今后它用，记忆），离目标越近的信息就是越需要的 重复和回归通常可以帮你确定目标 只要有可能，就把大块信息分解成小块，就不会感到困难了，分解信息会当你找出其中的规律和主题 纸质文档 与 电子文档 没有一个完美无缺的组织方法 通常消化吸收之后的信息，写下来会比较好 做笔记的过程就是锻炼信息筛选的过程，好的笔记不是全，而是精 共勉句 每当文件柜即将塞满的时候，我会直接筛选一遍文档，不再需要的财务票据及其它敏感信息，我会当场销毁，其它不用的文件继续回收利用 重要文档，必须纸质保存 信息多的时候，先分类，后处理 要使用信誉好的在线存储或备份业务 针对需要处理的信息，你要确定什么时候最可能用到，如何去使用，需要保存的期限有多长，以及你打算与谁共享，从而决定存储方式。 何时使用纸质工具 解决某个问题或者提出一种想法，请随时记录下来 目标是记住或者真正吸收的信息，打印出来比盯着屏幕要好 随身携带一个小笔记本 何时使用数字工具 需要与别人共享的信息 需要快速查看的信息 存储比较久的信息 电子邮箱 Gmail 在数字信息中加上相应的关键词，以便日后容易找到 共勉句 Gmail 是一种近乎理想的脚手架，简单易用，免费，容量大 标签比文件夹更有效，一封邮件可以拥有多个标签 aaronshicf9032+shopping@gmail.cn 简直爽的不要不要的，自动过滤 把密码提示线索保存在Gmail邮箱之类的便于访问的安全场所 日历 Google Calendar 跟特定人士共享特定日程，其实就是为他们过滤你的日程信息 尽量使用已经上手的工具 协同文档 Google doc 轻量级，适用于协作：存放重要本地文档、组织一个待办事项总清单、掌握资金使用情况、共享临时信息 每周拿出些时间回顾关键信息 也许是精华 如何减轻大脑的压力：及时加注解，有助于以后了解背景信息 思维转换：从一件事情过度到另一件事，转换气味的时候，大脑必须要吧短期记忆中的当前内容转移到长期记忆中，以便为新信息腾出空间，这样一来，有些信息就会丢失 思维转换次数越多，各种思维背景之间的关联度就月底，大脑的工作难度就越大 晚上要睡好，在你和你的大脑都能休息好的时候，转换思维要容易的多 如何减少思维转换的次数 当需要转换的时候，随手加上背景注解，方便下次直接还原当时的想法 把类似的任务或会议安排在一起 分辨哪些分神的因素导致频繁进行并不必要的思维转换，然后减少这些因素 心无旁骛的工作状态：定期查收邮件，关闭手机干扰，隔间里工作 召开会议之前先的明确会议主题和目标 把工作和生活融为一体，而不是力图在二者之间求平衡 在效率下降的时候自我放松一下，同时需要工作的时候随时工作 如何处理意外事件 无论如何都要”把握当前”，在危机出现之前，如果已经做到未雨绸缪，胸有成竹，那现在就会更加从容不迫，有备无患 在你面对重大挑战的时候，典型反应就是寻求更多信息 在出现危机时，依然具备处理好当前事情的能力，即掌控当前局面的能力，而这个能力需要实践经验的积累 你无法预知未来，但你可以确认正在发生的坏事表现出来的征兆，从而未雨绸缪，以便坏事发生时，知道如何应对 多跟哪些不同于自己的朋友沟通交流，这在艰难时期更加重要 过分的考虑未来情况，经常会失去对当前的把握 找工作：真的可以如此高效？ 面试的时候，希望对方记住你，那么请利用故事去记忆 仅仅因为一直都是按照某种特定方式做某事，并不意味着就该永远这样做 进行组织安排时，要绕开的是实际制约而不是假性制约，面试的时候要理清楚什么是自身的实际制约，才能专注于一个目标 每周拿出写关键事件回顾关键信息 学会面试记录：尽量使用已经上手的工具 + 在数字信息上加上相应的关键词","categories":[],"tags":[{"name":"读书","slug":"读书","permalink":"https://aaronshi32.github.io/tags/读书/"}],"keywords":[]}]}